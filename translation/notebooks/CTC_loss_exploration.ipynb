{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8yHyLHNaYGX",
        "outputId": "30298dda-1b8a-4760-c964-66d9fd188b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=c958fbab1a764cdf54af43c90abc6765be200c49015e5ec67b856927c6d9dac8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AatsqXl5AZpc",
        "outputId": "fc0556b5-9f20-45df-b455-ff1453740fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fast_align'...\n",
            "remote: Enumerating objects: 213, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 213 (delta 2), reused 4 (delta 2), pack-reused 204\u001b[K\n",
            "Receiving objects: 100% (213/213), 70.68 KiB | 3.53 MiB/s, done.\n",
            "Resolving deltas: 100% (110/110), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/clab/fast_align"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G69i1bQ6AcJ6",
        "outputId": "ba1b1070-77e9-4389-d94f-d3308ccd89e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 9.4.0\n",
            "-- The CXX compiler identification is GNU 9.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:2 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 2.8.12 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Could NOT find SparseHash (missing: SPARSEHASH_INCLUDE_DIR) \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/fast_align/build\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/fast_align.dir/src/fast_align.cc.o\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!mkdir fast_align/build\n",
        "!cd fast_align/build && cmake .. && make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZraE1WRMG9RI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import codecs\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlnlejuzYO8R",
        "outputId": "ba5771e9-f2b4-4217-f44c-8f3919a4c66b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Xb3XJzHIxt",
        "outputId": "26351974-cce9-4155-89f6-0b9c301bae58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGhMVdSgN0-4"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whir2DtxfQlO",
        "outputId": "4fef8b3e-56da-4622-9a5b-d4aa18647999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "europarl-v7.fr-en.en\n",
            "europarl-v7.fr-en.fr\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf '/content/drive/MyDrive/fr-en.tgz' -C '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEVOXadBf5JI"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/train.en.txt' '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiOwO5Fbf-mt",
        "outputId": "9c61a840-699a-44f4-eaca-c80e814598c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!cp '/content/drive/MyDrive/train.de.txt' '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQtveYf6gFEQ"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/dict.en-de.txt' '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp-yheBagQ29"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/newstest2014.en.txt' '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yr6tiD1gX8S"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/newstest2014.de.txt' '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oBt8NztG-4Y"
      },
      "outputs": [],
      "source": [
        "with open('/content/europarl-v7.fr-en.en', 'r') as f:\n",
        "    print(f.readlines()[:2])\n",
        "with open('/content/europarl-v7.fr-en.fr', 'r') as f:\n",
        "    print(f.readlines()[:2])\n",
        "\n",
        "with open('/content/train.de.txt', 'r') as f:\n",
        "    print(f.readlines()[:2])\n",
        "with open('/content/train.en.txt', 'r') as f:\n",
        "    print(f.readlines()[:2])\n",
        "with open('/content/dict.en-de.txt', 'r') as f:\n",
        "    print(''.join(f.readlines()[:100]))\n",
        "with open('/content/newstest2014.en.txt', 'r') as f:\n",
        "    t = f.readlines()\n",
        "    print(len(t))\n",
        "    print(t[:2])\n",
        "with open('/content/newstest2014.de.txt', 'r') as f:\n",
        "    t = f.readlines()\n",
        "    print(len(t))\n",
        "    print(t[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdMZaqDlkToP",
        "outputId": "b8127a9f-849a-426e-d463-fbcba729ffdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumption of the session\n",
            "\n",
            "I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
            "\n",
            "Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
            "\n",
            "You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
            "\n",
            "In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
            "\n",
            "Please rise, then, for this minute' s silence.\n",
            "\n",
            "(The House rose and observed a minute' s silence)\n",
            "\n",
            "Madam President, on a point of order.\n",
            "\n",
            "You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.\n",
            "\n",
            "One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('/content/europarl-v7.fr-en.en', 'r') as f:\n",
        "    print('\\n'.join(f.readlines()[:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcDaDA1us27E"
      },
      "outputs": [],
      "source": [
        "def read_data(read_paths, save_path, maxlen=30, langs=['german', 'english'], maxsize=5000000):\n",
        "    lang_from, lang_to = langs\n",
        "\n",
        "    input_file_lang1 = codecs.open(read_paths[0], 'r', 'utf-8')\n",
        "    input_file_lang2 = codecs.open(read_paths[1], 'r', 'utf-8')\n",
        "    output_file = codecs.open(save_path, 'w', 'utf-8')\n",
        "\n",
        "    for i, (line1, line2) in tqdm(enumerate(zip(input_file_lang1, input_file_lang2))):\n",
        "        content1, content2 = line1.strip().lower(), line2.strip().lower()\n",
        "        tokenized_content1 = word_tokenize(content1, language=langs[0])\n",
        "        tokenized_content2 = word_tokenize(content2, language=langs[1])\n",
        "        if len(tokenized_content1) < maxlen \\\n",
        "            and len(tokenized_content2) < maxlen \\\n",
        "            and len(tokenized_content1) > 1 \\\n",
        "            and len(tokenized_content2) > 1:\n",
        "            output_file.write(content1 + ' ||| ' + content2 + '\\n')\n",
        "\n",
        "        if i > maxsize:\n",
        "            break\n",
        "\n",
        "    input_file_lang1.close()\n",
        "    input_file_lang2.close()\n",
        "    output_file.close()\n",
        "\n",
        "\n",
        "def read_vocab_from_corpus(vocab_path, save_path, capacity=50000, lang='english'):\n",
        "    counts = defaultdict(int)\n",
        "    input_file = codecs.open(vocab_path, 'r', 'utf-8')\n",
        "    output_file = codecs.open(save_path, 'w', 'utf-8')\n",
        "\n",
        "    for line in tqdm(input_file):\n",
        "        content = line.strip().lower()\n",
        "        tokenized_content = word_tokenize(content, language=lang)\n",
        "        for word in tokenized_content:\n",
        "            counts[word] += 1\n",
        "\n",
        "    picked_words = sorted(counts.keys(), key=lambda x: counts[x], reverse=True)[:capacity]\n",
        "    for word in picked_words:\n",
        "        output_file.write(word + '\\n')\n",
        "            \n",
        "    input_file.close()\n",
        "    output_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "2d6aabbff5cc4e2da3aead804acd3a1a",
            "dc4551c6a2d74c5cb064c5569100b119",
            "852e77daec144f089d0662237831a046",
            "279f11a561134e539e07b81eba1b20f6",
            "f23caa1c7f3943f0a35df5e9209b1506",
            "97e700609be747248d700fcdd7e9ae73",
            "6a66ce5c04324787b25bb01321ed2691",
            "fdad38d2e5c74fcfb658ee996002cb7f",
            "93d112fc010f4ed389db9a123ee9475f",
            "c4091b85a534428d850c98fea1f24673",
            "4ffae02276a8408fa78ae2829c16951c",
            "1d3572c0077348a881a005e01c4f448b",
            "539d4137c92a472e80ccf3025e7f550a",
            "a1c2617188b64744a8c014202f75e9bf",
            "553a93cf5a6e4d6195e86e9c84ba3adb",
            "7e50feb0d118481e9b428e98d8a194ec",
            "f854308a3b15459e9d04db15afe01689",
            "ff37553fc5144fa0a29eeffdecbd8284",
            "5d4a451572264a4090ebbd3538746b93",
            "2b6451eceb2e4a41be58dd3352f0f2cd",
            "f21421803d6f450ea9f576a2a98de127",
            "dffdde6dccab47ad9cd6ef0c8dee70bf",
            "ea07a8226ab9431f88298980914e196e",
            "bfe44cad8a5741ffb02387c267fcd604",
            "2cd35d11eb624c5b8f2ecf88ad8203dc",
            "ac6923958e13466ba7e8ed2019451a4c",
            "057043f95f9244f1af63816c77dbc79f",
            "594de13f96cc43d89249ea570b0bb1c6",
            "29660b40777a43ed84b8fdb0a0b04a5a",
            "ce36610875874f6487c7f29a6f394834",
            "b81ad2b34be74bfaa790757b5b64298f",
            "2d45fb7c805a4436ac546ccb82076f75",
            "f00538d27fed4f0fb768bcbdaacb0f53",
            "0ab40f6e365944e7a44542c558190cb4",
            "b22ce93b28ba4ecabea756ee75641172",
            "5f936c2664bb4dad96248ad245629c59",
            "c377a4ba58db40d59985c538741ced61",
            "17bf3e4281404f5cacc0b31874bccb24",
            "467c930de4464625a622f2458aab28a6",
            "803e0d8755bd4886902df945fe3bd7a9",
            "2ff43c344d7a47649533c3f563e48867",
            "4b14ac5b1d9943efb0cc499adb124c28",
            "d4f74adbd434402184e46a8725bbd538",
            "ef48e9b3d60049cf80f45f5f5ce85692"
          ]
        },
        "id": "r0UlPJOTltl_",
        "outputId": "af134414-ba94-41b3-a4ae-62b767a47e09"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d6aabbff5cc4e2da3aead804acd3a1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d3572c0077348a881a005e01c4f448b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea07a8226ab9431f88298980914e196e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ab40f6e365944e7a44542c558190cb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!rm -r vocab\n",
        "!mkdir vocab\n",
        "read_vocab_from_corpus('/content/train.de.txt', '/content/vocab/wmt14.de', lang='german')\n",
        "read_vocab_from_corpus('/content/train.en.txt', '/content/vocab/wmt14.en', lang='english')\n",
        "read_data(['/content/newstest2014.de.txt', '/content/newstest2014.en.txt'], '/content/parallel_en_de_newstest.txt')\n",
        "read_data(['/content/train.de.txt', '/content/train.en.txt'], '/content/parallel_en_de_train.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0tDFHWInlcV",
        "outputId": "444d7ed5-6a05-4ba2-85d0-e2f34f45d8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1639\n",
            "orlando bloom und miranda kerr lieben sich noch immer ||| orlando bloom and miranda kerr still love each other\n",
            "\n",
            "schauspieler orlando bloom und model miranda kerr wollen künftig getrennte wege gehen . ||| actors orlando bloom and model miranda kerr want to go their separate ways .\n",
            "\n",
            "in einem interview sagte bloom jedoch , dass er und kerr sich noch immer lieben . ||| however , in an interview , bloom has said that he and kerr still love each other .\n",
            "\n",
            "schauspieler orlando bloom hat sich zur trennung von seiner frau , topmodel miranda kerr , geäußert . ||| actor orlando bloom announced his separation from his wife , supermodel miranda kerr .\n",
            "\n",
            "&quot; wir werden uns gegenseitig unterstützen und lieben als eltern von flynn &quot; . ||| &quot; we &apos;re going to support one another and love each other as parents to flynn &quot; .\n",
            "\n",
            "kerr und bloom sind seit 2010 verheiratet , im jahr 2011 wurde ihr söhnchen flynn geboren . ||| kerr and bloom have been married since 2010 . their son flynn was born in 2011 .\n",
            "\n",
            "jumbo ##at##-##at## hersteller streiten im angesicht großer bestellungen über sitzbreite ||| jet makers feud over seat width with big orders at stake\n",
            "\n",
            "flugzeuggiganten teilen häufig hiebe über technische details mittels werbung in der fachpresse aus . ||| plane giants often trade blows on technical matters through advertising in the trade press .\n",
            "\n",
            "jetzt appelliert airbus vor der dubai airshow , wo die 777x mit über 100 bestellungen voraussichtlich das rennen machen wird , direkt an die öffentlichkeit . ||| now , airbus is appealing directly to the public ahead of the dubai airshow , where the 777x is expected to dominate with more than 100 orders .\n",
            "\n",
            "angesichts geänderter ernährungsgewohnheiten werden die leute dicker , doch flugzeugsitze haben sich nicht radikal verändert . ||| as diets change , people get bigger but plane seating has not radically changed .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('/content/parallel_en_de_newstest.txt', 'r') as f:\n",
        "    t = f.readlines()\n",
        "    print(len(t))\n",
        "    print('\\n'.join(t[:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZTZ0s_VAsSX"
      },
      "outputs": [],
      "source": [
        "!./fast_align/build/fast_align -i parallel_en_de_train.txt -d -o -v > forward.align.train\n",
        "!./fast_align/build/fast_align -i parallel_en_de_train.txt -d -o -v -r > reverse.align.train\n",
        "!./fast_align/build/atools -i forward.align.train -j reverse.align.train -c grow-diag-final-and > symmetric_train_align.txt\n",
        "\n",
        "!./fast_align/build/fast_align -i parallel_en_de_newstest.txt -d -o -v > forward.align.newstest\n",
        "!./fast_align/build/fast_align -i parallel_en_de_newstest.txt -d -o -v -r > reverse.align.newstest\n",
        "!./fast_align/build/atools -i forward.align.newstest -j reverse.align.newstest -c grow-diag-final-and > symmetric_newstest_align.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvAam6Hte2oQ",
        "outputId": "ad9adae8-a806-4b97-a83c-765a6eaeb786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1781990\n",
            "1639\n"
          ]
        }
      ],
      "source": [
        "with open('/content/symmetric_train_align.txt', 'r') as f:\n",
        "    print(len(f.readlines()))\n",
        "with open('/content/symmetric_newstest_align.txt', 'r') as f:\n",
        "    print(len(f.readlines()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S_AmYQfmpVLe"
      },
      "outputs": [],
      "source": [
        "# !cp '/content/symmetric_train_align.txt' '/content/drive/MyDrive/CTC_in_NLP/symmetric_train_align.txt'\n",
        "# !cp '/content/symmetric_newstest_align.txt' '/content/drive/MyDrive/CTC_in_NLP/symmetric_newstest_align.txt'\n",
        "# !cp '/content/forward.align.newstest' '/content/drive/MyDrive/CTC_in_NLP/forward.align.newstest'\n",
        "# !cp '/content/forward.align.train' '/content/drive/MyDrive/CTC_in_NLP/forward.align.train'\n",
        "# !cp '/content/reverse.align.newstest' '/content/drive/MyDrive/CTC_in_NLP/reverse.align.newstest'\n",
        "# !cp '/content/reverse.align.train' '/content/drive/MyDrive/CTC_in_NLP/reverse.align.train'\n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/symmetric_train_align.txt' '/content/symmetric_train_align.txt'\n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/symmetric_newstest_align.txt' '/content/symmetric_newstest_align.txt'\n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/forward.align.newstest' '/content/forward.align.newstest'\n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/forward.align.train' '/content/forward.align.train'\n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/reverse.align.newstest' '/content/reverse.align.newstest'\n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/reverse.align.train' '/content/reverse.align.train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-0VmRF9oWn6",
        "outputId": "d52b96b7-1e7b-46c0-aa51-213fd9642cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'vocab': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !cp '/content/parallel_en_de_newstest.txt' '/content/drive/MyDrive/CTC_in_NLP/parallel_en_de_newstest.txt'\n",
        "# !cp '/content/parallel_en_de_train.txt' '/content/drive/MyDrive/CTC_in_NLP/parallel_en_de_train.txt'\n",
        "# !cp '/content/vocab/wmt14.de' '/content/drive/MyDrive/CTC_in_NLP/wmt14.de'\n",
        "# !cp '/content/vocab/wmt14.en' '/content/drive/MyDrive/CTC_in_NLP/wmt14.en'\n",
        "!rm -r vocab\n",
        "!mkdir vocab\n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/parallel_en_de_newstest.txt' '/content/parallel_en_de_newstest.txt' \n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/parallel_en_de_train.txt' '/content/parallel_en_de_train.txt' \n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/wmt14.de' '/content/vocab/wmt14.de' \n",
        "!cp '/content/drive/MyDrive/CTC_in_NLP/wmt14.en' '/content/vocab/wmt14.en' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "09QWzrzTNnIN"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, lang='english', capacity=20000, maxsize=10000000):\n",
        "        self.t2i = {'<PAD>': 0, '<UNK>': 1, '<CTC>': 2, '<SOS>': 3, '<EOS>': 4}\n",
        "        self.i2t = {0: '<PAD>', 1: '<UNK>', 2: '<CTC>', 3: '<SOS>', 4: '<EOS>'}\n",
        "        self.lang = lang\n",
        "        self.capacity = capacity\n",
        "        self.maxsize = maxsize\n",
        "\n",
        "    def load(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            for line in tqdm(f.readlines()):\n",
        "                word = line.strip().lower()\n",
        "                self.t2i[word] = len(self.t2i)\n",
        "                self.i2t[self.t2i[word]] = word\n",
        "        return self\n",
        "                \n",
        "class TrDataset(Dataset):\n",
        "    def __init__(self, paths, vocabs, langs):\n",
        "        self.vocabs = dict([(lang, vocab) for lang, vocab in zip(langs, vocabs)])\n",
        "        self.path, self.alignment_path = paths\n",
        "        self.data = dict([(lang, []) for lang in langs])\n",
        "        self.alignments = []\n",
        "        self.langs = langs\n",
        "        self.delim = ' ||| '\n",
        "        \n",
        "        input_file = codecs.open(self.path, 'r', 'utf-8')\n",
        "        alignment_file = codecs.open(self.alignment_path, 'r', 'utf-8')\n",
        "\n",
        "        for input_line, alignment_line in tqdm(zip(input_file, alignment_file)):\n",
        "            lines = input_line.strip().split(self.delim)\n",
        "            unk_count = dict(zip(langs, [0 for lang in langs]))\n",
        "            lengths = dict()\n",
        "            for line, lang in zip(lines, langs):\n",
        "                content = line.strip().lower()\n",
        "                tokenized_content = word_tokenize(content, language=lang)\n",
        "                content_tokens = [self.vocabs[lang].t2i['<SOS>']]\n",
        "                for word in tokenized_content:\n",
        "                    if word in self.vocabs[lang].t2i:\n",
        "                        content_tokens.append(self.vocabs[lang].t2i[word])\n",
        "                    else:\n",
        "                        unk_count[lang] += 1\n",
        "                        content_tokens.append(self.vocabs[lang].t2i['<UNK>'])\n",
        "                content_tokens.append(self.vocabs[lang].t2i['<EOS>'])\n",
        "                self.data[lang].append(content_tokens)\n",
        "                lengths[lang] = len(content_tokens)\n",
        "            if unk_count[langs[0]] > 0.4 * lengths[langs[0]] or unk_count[langs[1]] > 0.4 * lengths[langs[1]]:\n",
        "                self.data[langs[0]].pop()\n",
        "                self.data[langs[1]].pop()\n",
        "                continue\n",
        "            alignment_matrix = torch.zeros((lengths[langs[1]], lengths[langs[0]]), dtype=torch.int64)\n",
        "            for alignment in alignment_line.strip().split(' '):\n",
        "                i, j = map(int, alignment.split('-'))\n",
        "                alignment_matrix[j + 1][i + 1] += 1\n",
        "            alignment_matrix[0, 0] = 1\n",
        "            alignment_matrix[-1, -1] = 1\n",
        "\n",
        "            self.alignments.append(alignment_matrix)\n",
        "                    \n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return [torch.LongTensor(self.data[lang][idx]) for lang in self.langs] + [torch.LongTensor(self.alignments[idx])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[self.langs[0]])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    l1, l2, m = list(zip(*batch))\n",
        "    l1, l2 = pad_sequence(l1 + l2, batch_first=True)[:len(l1)], pad_sequence(l2 + l1, batch_first=True)[:len(l2)]\n",
        "    m = list(m)\n",
        "    for i, matrix in enumerate(m):\n",
        "        eye = torch.eye(max(l1.shape[1], l2.shape[1]))\n",
        "        eye[:matrix.shape[0], :matrix.shape[1]] = matrix\n",
        "        m[i] = eye\n",
        "    m = torch.stack(m, dim=0)\n",
        "    return l1, l2, m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSOLcQU-RrW6",
        "outputId": "71deaa0f-64ef-479a-e7af-844aac3699c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ff28b947224840e7930e145be1abeb56",
            "2c6e76ac7f144378bebdefc0bfce359e",
            "9028c4d7356c40899af72097455e81cc",
            "443d5ef229a6479d861e6cb6470fe962",
            "54432c28b5a74313bf67cbdee2e58cd8",
            "e82974a814ed4dffbaa3369a76f42597",
            "c1d612f9fd344593923bae6a7432310f",
            "3309730587ca4d1990109e1be31b9ee9",
            "32b752136ff9445db80122898004c61a",
            "ac26bf0839f5447fb3fdb59426aed8ee",
            "c8d40b1fb9854dbabde94b8f2e23b86c",
            "1fb52dd18278454085d444c97b75c8dc",
            "0ab6b54b4107405f8ad989265f5f03de",
            "7565f27d6f5741eea8ee7be6a77d01c2",
            "f84c2dc87a384afeaff6be0eacd793f4",
            "61d1c0c8084944548e0d8006415512ad",
            "7607aa00475d4522a95e9e7e00f2cef3",
            "cbdd01642da54154a4fcb349aefee808",
            "4b1dfb5f1d5c4511a63bdff39f9b9de0",
            "308726f6179049bb877b4197139e3ded",
            "70c0de2862f6470ea07f6354681dd02a",
            "5b22df2ae74e46b08eeddaf1f3cc6e2c",
            "1fbced3ac92d4a34b112297a1f9a692c",
            "7a83d592dcd040be9608ca1176241a67",
            "629d80f0a77844379d9bf6188a2470f5",
            "3778c6178420426b8aabaa7c3d09bfce",
            "a1db28d6ef104e9c9fed42cd3f081724",
            "f7d49c47fe6b4d2b8ab3508c993e9185",
            "d960a9a9d8ed4b8c99cee2106ed6e48a",
            "313fb0f31b40465b8e4ea9fcfdbe8692",
            "8b4128cd05414acabbe566c48c3e79ff",
            "314de1087d4c4eafa42af96488df4f67",
            "7470fe2f15d94d41b23204f7d38b0ecb",
            "2d4d5985d1874f25ad87de5eeae1c383",
            "6ce16c3368b5402aafd70cc186316544",
            "7e24b8c2fe6541b480354b54b4cb92f5",
            "fd54dca48bbe44199bac37756b37e4b7",
            "6ffa047d8d5849c79e6a3e2f61f18d1e",
            "5e40bebfdb0b4115805188e79e231dd4",
            "c768b05c93c94f5e9202d735c1683882",
            "945d561cabd34e7f97c6f4c20fcc4c58",
            "6bd28c5cdc32412f940c3a93017e3a49",
            "6dc2803c33e34d7280cc4f53ae0034d7",
            "a857df531c614bc8855f6aae89adab76"
          ]
        },
        "id": "Y7xcNlgwXVOo",
        "outputId": "650656cb-cae7-4766-8ab5-ffba50551dd5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff28b947224840e7930e145be1abeb56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fb52dd18278454085d444c97b75c8dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fbced3ac92d4a34b112297a1f9a692c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d4d5985d1874f25ad87de5eeae1c383"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "vocabs = [Vocab(lang='german').load('/content/vocab/wmt14.de'),\n",
        "          Vocab(lang='english').load('/content/vocab/wmt14.en')]\n",
        "langs = ['german', 'english']\n",
        "train_dataset = TrDataset(['/content/parallel_en_de_train.txt', '/content/symmetric_train_align.txt'], vocabs, langs)\n",
        "test_dataset = TrDataset(['/content/parallel_en_de_newstest.txt', '/content/symmetric_newstest_align.txt'], vocabs, langs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Bm6pUAs8Ry",
        "outputId": "3c42edc6-a290-4e75-bff4-a08b56c785aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1774415, 1638)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EKHSgcpSh_ED"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdkC1d8ciGBL",
        "outputId": "969d2bda-73c9-47f9-d93a-d9bb8430e4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 31])\n"
          ]
        }
      ],
      "source": [
        "for batch in val_loader:\n",
        "    print(batch[0].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sQkLDqDBX0mU"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, index_dim, embedding_dim=256, hidden_dim=256, dropout=0.2, layers=2):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(index_dim, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.directions = 2\n",
        "        self.layers = layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        mask = (x != 0).to(torch.long)\n",
        "        lengths = mask.sum(dim=1).to('cpu')\n",
        "\n",
        "        emb = self.embedding(x)\n",
        "        emb = pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)\n",
        "        out, hidden = self.lstm(emb)\n",
        "        out, _ = pad_packed_sequence(out, batch_first=True)\n",
        "        return self.dropout(out), hidden\n",
        "\n",
        "\n",
        "class LSTMAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim, attention_dim, directions=2):\n",
        "        super(LSTMAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_dim * directions, attention_dim)\n",
        "        self.W2 = nn.Linear(hidden_dim * directions, attention_dim)\n",
        "        self.V = nn.Linear(attention_dim, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)    \n",
        "\n",
        "    def forward(self, hidden, enc_out):\n",
        "        score = self.V(self.tanh(self.W1(enc_out) + self.W2(hidden.view(hidden.shape[1], -1).unsqueeze(1)))).squeeze(-1)\n",
        "        attention_weights = self.softmax(score)\n",
        "        assert len(attention_weights.shape) == 2\n",
        "        \n",
        "        context_vector = attention_weights.unsqueeze(-1) * enc_out\n",
        "        context_vector = context_vector.sum(axis=1)\n",
        "        return context_vector\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, index_dim, embedding_dim=256, hidden_dim=256, attention_dim=128, enc_directions=2):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.attention = LSTMAttention(hidden_dim, attention_dim)\n",
        "        self.embedding = nn.Embedding(index_dim, embedding_dim)\n",
        "        self.linear = nn.Linear(hidden_dim * enc_directions, index_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + hidden_dim * enc_directions, hidden_dim * enc_directions, batch_first=True)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, hidden, enc_out):\n",
        "        context_vector = self.attention(hidden[0], enc_out)\n",
        "        emb = self.relu(self.embedding(x))\n",
        "        emb = torch.cat([context_vector.unsqueeze(1), emb], dim=-1)\n",
        "        out, hidden = self.lstm(emb, hidden)\n",
        "        out = self.linear(out)\n",
        "        return out, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, attention_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        self.Q = nn.Linear(hidden_dim, attention_dim)\n",
        "        self.K = nn.Linear(hidden_dim, attention_dim)\n",
        "        self.V = nn.Linear(hidden_dim, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)    \n",
        "\n",
        "    def forward(self, x):\n",
        "        Qw = self.Q(x)\n",
        "        Kw = self.K(x)\n",
        "        Vw = self.V(x)\n",
        "        attention_weights = (self.softmax(Qw@(Kw.permute(0, 2, 1)))@Vw).squeeze(-1)\n",
        "        assert len(attention_weights.shape) == 2\n",
        "        \n",
        "        context_vector = attention_weights.unsqueeze(-1) * x\n",
        "        return context_vector\n",
        "\n",
        "class GatedAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim, attention_dim):\n",
        "        super(GatedAttention, self).__init__()\n",
        "        self.Q = nn.Linear(hidden_dim, attention_dim)\n",
        "        self.K = nn.Linear(hidden_dim, attention_dim)\n",
        "        self.V = nn.Linear(attention_dim, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)    \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        Qw = self.Q(x)\n",
        "        Kw = self.K(x)\n",
        "\n",
        "        g = self.sigmoid(self.V(Qw)).squeeze(-1)\n",
        "        M = torch.diag(torch.ones((x.shape[1])) * -torch.inf).repeat(x.shape[0], 1, 1).to(device=x.device)\n",
        "        D = torch.diag_embed(g).to(device=x.device)\n",
        "        I = torch.diag(torch.ones((x.shape[1]))).repeat(x.shape[0], 1, 1).to(device=x.device)\n",
        "        P = self.softmax(M + Qw@(Kw.permute(0, 2, 1)))\n",
        "        P = D + (I - D) @ P\n",
        "        return P\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout = 0.1, max_len = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "# The duplication predictor and grouping predictor modules consist of \n",
        "# a convolutional layer, \n",
        "# ReLU activation, \n",
        "# layer normalization, \n",
        "# dropout,\n",
        "# a projection layer (convs + linear -> how????), same as the phoneme duration predictor in FastSpeech (Ren et al., 2019), which is a parallel text-to-speech model.\n",
        "\n",
        "class GroupsLoss(nn.Module):\n",
        "    def __init__(self, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, probs):\n",
        "        return -torch.log(self.softmax(probs)).mean(dim=-1)\n",
        "\n",
        "\n",
        "class LengthClassDuplicationModule(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, max_duplication=3):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(input_dim, hidden_dim, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.projection = nn.Linear(hidden_dim, max_duplication)\n",
        "        self.ln = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.max_duplication = max_duplication\n",
        "\n",
        "    def forward(self, x):\n",
        "        lengths_probs = self.projection(self.dropout(self.ln(self.relu(self.conv(x.permute(0, 2, 1)).permute(0, 2, 1)))))\n",
        "        lengths = torch.cumsum(torch.argmax(lengths_probs, dim=-1).unsqueeze(1) + 1, dim=-1)\n",
        "        duplication_matrix = torch.zeros((x.shape[0], x.shape[1] * self.max_duplication, x.shape[1])) + torch.arange(1, 1 + x.shape[1] * self.max_duplication).unsqueeze(0).unsqueeze(2)\n",
        "        duplication_matrix = duplication_matrix.to(device=x.device)\n",
        "        duplication_matrix[:, :, 0] = torch.clamp(lengths[:, :, 0] - duplication_matrix[:, :, 0] + 1, 0, 1)\n",
        "        duplication_matrix[:, :, 1:] = torch.clamp(lengths[:, :, 1:] - duplication_matrix[:, :, 1:] + 1, 0, 1) * torch.clamp(duplication_matrix[:, :, 1:] - lengths[:, :, :-1], 0, 1)\n",
        "\n",
        "        #nn.parallel.parallel_apply([lambda x: torch.repeat_interleave(x[i], lengths[i], dim=1) for i in range(x.shape[0])], x)\n",
        "        return lengths_probs, duplication_matrix\n",
        "\n",
        "\n",
        "class LengthRegDuplicationModule(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, max_duplication=3):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(input_dim, hidden_dim, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.projection = nn.Linear(hidden_dim, 1)\n",
        "        self.ln = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.max_duplication = max_duplication\n",
        "\n",
        "    def forward(self, x):\n",
        "        lengths = torch.clamp(self.projection(self.dropout(self.ln(self.relu(self.conv(x.permute(0, 2, 1)).permute(0, 2, 1))))).squeeze(-1), 0, self.max_duplication - 1)\n",
        "        lengths = torch.cumsum(lengths.floor().unsqueeze(1) + 1, dim=-1)\n",
        "        duplication_matrix = torch.zeros((x.shape[0], x.shape[1] * self.max_duplication, x.shape[1])) + torch.arange(1, 1 + x.shape[1] * self.max_duplication).unsqueeze(0).unsqueeze(2)\n",
        "        duplication_matrix = duplication_matrix.to(device=x.device)\n",
        "        duplication_matrix[:, :, 0] = torch.clamp(lengths[:, :, 0] - duplication_matrix[:, :, 0] + 1, 0, 1)\n",
        "        duplication_matrix[:, :, 1:] = torch.clamp(lengths[:, :, 1:] - duplication_matrix[:, :, 1:] + 1, 0, 1) * torch.clamp(duplication_matrix[:, :, 1:] - lengths[:, :, :-1], 0, 1)\n",
        "\n",
        "        #nn.parallel.parallel_apply([lambda x: torch.repeat_interleave(x[i], lengths[i], dim=1) for i in range(x.shape[0])], x)\n",
        "        return duplication_matrix\n",
        "\n",
        "\n",
        "class GroupingModule(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(input_dim, hidden_dim, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.projection = nn.Linear(hidden_dim, 2)\n",
        "        self.ln = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        groups_probs = self.projection(self.dropout(self.ln(self.relu(self.conv(x.permute(0, 2, 1)).permute(0, 2, 1)))))\n",
        "        groups = torch.argmax(groups_probs, dim=-1) # [batch, length]\n",
        "        groups[:, 0] = 0\n",
        "        start_groups = groups.nonzero(as_tuple=True)\n",
        "        last_group = groups.shape[1]\n",
        "        groups = torch.cumsum(torch.ones(groups.shape).to(device=x.device), dim=-1)\n",
        "        groups[:, 0] = 0\n",
        "        groups[start_groups[0], start_groups[1]] = 0\n",
        "        groups[:, -1] = last_group\n",
        "        groups = torch.gather(groups, 1, groups.ne(0).to(dtype=torch.int).argsort(dim=1, descending=True, stable=True)).unsqueeze(2)\n",
        "        grouping_matrix = torch.zeros((x.shape[0], x.shape[1], x.shape[1])) + torch.arange(1, 1 + x.shape[1]).unsqueeze(0).unsqueeze(1)\n",
        "        grouping_matrix = grouping_matrix.to(device=x.device)\n",
        "        grouping_matrix[:, 0, :] = torch.clamp(groups[:, 0, :] - grouping_matrix[:, 0, :] + 1, 0, 1)\n",
        "        grouping_matrix[:, 1:, :] = torch.clamp(groups[:, 1:, :] - grouping_matrix[:, 1:, :] + 1, 0, 1) * torch.clamp(grouping_matrix[:, 1:, :] - groups[:, :-1, :], 0, 1)\n",
        "\n",
        "        #nn.parallel.parallel_apply([lambda x: torch.repeat_interleave(x[i], lengths[i], dim=1) for i in range(x.shape[0])], x)\n",
        "        return groups_probs, grouping_matrix\n",
        "\n",
        "\n",
        "# The permutation predictor in Aligner consists of three encoder layers: \n",
        "# pre-network, query/key network, and single-head attention module for the outputs.\n",
        "class PermutationModule(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, attention_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.ModuleList([\n",
        "            nn.Linear(input_dim, hidden_dim), Attention(hidden_dim, attention_dim), \n",
        "            nn.Linear(hidden_dim, hidden_dim), Attention(hidden_dim, attention_dim)])\n",
        "        self.pre_net = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.gated_attention = GatedAttention(hidden_dim, attention_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.encoder:\n",
        "            x = layer(x)\n",
        "        return self.gated_attention(self.pre_net(x))\n",
        "\n",
        "\n",
        "class CTCDecoder(nn.Module):\n",
        "    def __init__(self, index_dim, hidden_dim=512):\n",
        "        super(CTCDecoder, self).__init__()\n",
        "        self.ctc_linear = nn.Linear(hidden_dim, index_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = torch.repeat_interleave(x.permute(1, 0, 2), 1, dim=1)\n",
        "        return self.softmax(self.ctc_linear(x.permute(1, 0, 2)))\n",
        "\n",
        "\n",
        "class CTCTransformerDecoder(nn.Module):\n",
        "    def __init__(self, index_dim, hidden_dim=512, heads=4):\n",
        "        super(CTCTransformerDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(index_dim, hidden_dim, padding_idx=0)\n",
        "        self.decoder = nn.TransformerDecoderLayer(d_model=hidden_dim, nhead=heads, dim_feedforward=512)\n",
        "        self.ctc_linear = nn.Linear(hidden_dim, index_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = torch.repeat_interleave(x.permute(1, 0, 2), 1, dim=1)\n",
        "        # y = torch.zeros(x.shape).uniform_(-0.1, 0.1).to(device=x.device) \n",
        "        # y = self.embedding(self.softmax(self.ctc_linear(x)).argmax(-1))\n",
        "        return self.softmax(self.ctc_linear(self.decoder(x, x))).permute(1, 0, 2)\n",
        "\n",
        "\n",
        "class Seq2CTC(nn.Module):\n",
        "    def __init__(self, encoder_index_dim, decoder_index_dim, hidden_dim=256):\n",
        "        super(Seq2CTC, self).__init__()\n",
        "        self.encoder = Encoder(encoder_index_dim, hidden_dim=hidden_dim)\n",
        "        self.ctc = CTCDecoder(decoder_index_dim)\n",
        "        # self.output_mask = OutputMask(2 * hidden_dim)\n",
        "        self.encoder_index_dim = encoder_index_dim\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        batch_size = x.shape[0]\n",
        "        device = x.device\n",
        "\n",
        "        input_length = x.shape[1]\n",
        "\n",
        "        enc_out, _ = self.encoder(x)\n",
        "\n",
        "        enc_out = nn.functional.pad(enc_out, (0, 0, 0, enc_out.shape[1]), \"constant\", 0)\n",
        "        \n",
        "        # mask = self.output_mask(enc_out.permute(1, 0, 2))\n",
        "        # ctc = torch.mul(mask.unsqueeze(-1), self.ctc(enc_out.permute(1, 0, 2)))\n",
        "\n",
        "        return self.ctc(enc_out.permute(1, 0, 2))\n",
        "\n",
        "class Transformer2CTC(nn.Module):\n",
        "    def __init__(self, encoder_index_dim, decoder_index_dim, embedding_dim=256, \n",
        "                 heads=4, hidden_dim=256, layers=4, dropout = 0.3):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(embedding_dim, heads, hidden_dim, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, layers)\n",
        "        self.encoder = nn.Embedding(encoder_index_dim, embedding_dim)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.decoder = CTCDecoder(decoder_index_dim, hidden_dim)\n",
        "        # self.output_mask = OutputMask(hidden_dim=hidden_dim)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        # x = nn.functional.pad(x, (0, 0, 0, x.shape[0]), \"constant\", 0)\n",
        "        x = self.encoder(x) * math.sqrt(self.embedding_dim)\n",
        "        x = self.pos_encoder(x)\n",
        "        output = self.transformer_encoder(x, mask)\n",
        "        # out_mask = self.output_mask(output)\n",
        "        # output = torch.mul(out_mask.unsqueeze(-1), self.decoder(output))\n",
        "        return self.decoder(output)\n",
        "\n",
        "\n",
        "class Transformer2TransformerCTC(nn.Module):\n",
        "    def __init__(self, encoder_index_dim, decoder_index_dim, embedding_dim=256, \n",
        "                 heads=4, hidden_dim=256, layers=4, dropout = 0.3):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(embedding_dim, heads, hidden_dim, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, layers)\n",
        "        self.encoder = nn.Embedding(encoder_index_dim, embedding_dim)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.decoder = CTCTransformerDecoder(decoder_index_dim, hidden_dim)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        # x = nn.functional.pad(x, (0, 0, 0, x.shape[0]), \"constant\", 0)\n",
        "        x = self.encoder(x) * math.sqrt(self.embedding_dim)\n",
        "        x = self.pos_encoder(x)\n",
        "        output = self.transformer_encoder(x, mask)\n",
        "        # out_mask = self.output_mask(output)\n",
        "        # output = torch.mul(out_mask.unsqueeze(-1), self.decoder(output))\n",
        "        return self.decoder(output)\n",
        "\n",
        "\n",
        "class AligNART(nn.Module):\n",
        "    def __init__(self, encoder_index_dim, decoder_index_dim, embedding_dim=256, \n",
        "                 heads=4, hidden_dim=256, layers=4, dropout = 0.3):\n",
        "        super().__init__()\n",
        "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(embedding_dim, heads, hidden_dim, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, layers)\n",
        "        self.encoder = nn.Embedding(encoder_index_dim, embedding_dim)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.decoder = CTCTransformerDecoder(decoder_index_dim, hidden_dim)\n",
        "        self.permute = PermutationModule(hidden_dim, hidden_dim, hidden_dim)\n",
        "        self.group = GroupingModule(hidden_dim, hidden_dim)\n",
        "        self.duplicate = LengthClassDuplicationModule(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x, mask, gt=None):\n",
        "        x = self.encoder(x) * math.sqrt(self.embedding_dim)\n",
        "        x = self.pos_encoder(x)\n",
        "        enc_output = self.transformer_encoder(x, mask).permute(1, 0, 2)\n",
        "        duplication_probs, duplication_matrix = self.duplicate(enc_output)\n",
        "        output = self.pos_encoder(gt[0]@enc_output) if gt is not None else self.pos_encoder(duplication_matrix@enc_output)\n",
        "        permutation_matrix = self.permute(output)\n",
        "        if gt is not None:\n",
        "            output = gt[1]@output \n",
        "        else:\n",
        "            permutation_matrix = permutation_matrix.cpu().detach().numpy()\n",
        "            eye = np.eye(permutation_matrix.shape[1], permutation_matrix.shape[2])\n",
        "            for i in range(permutation_matrix.shape[0]):\n",
        "                try:\n",
        "                    permutation_matrix[i] += 1e-16\n",
        "                    xs, ys = linear_sum_assignment(-1 * np.log(permutation_matrix[i]))\n",
        "                    permutation_matrix[i] *= 0\n",
        "                    permutation_matrix[i, xs, ys] = 1\n",
        "                    ones = int(permutation_matrix[i].sum())\n",
        "                    permutation_matrix[i][ones:, ones:] = eye[ones:, ones:]\n",
        "                except Exception as e:\n",
        "                    permutation_matrix[i] = eye\n",
        "                    print(\"Warning: permutation_matrix \", e)\n",
        "            permutation_matrix = torch.Tensor(permutation_matrix).to(device=x.device)\n",
        "            output = permutation_matrix@output\n",
        "        grouping_probs, grouping_matrix = self.group(output)\n",
        "        if gt is not None:\n",
        "            alignment = gt[2]@gt[1]@gt[0]\n",
        "            output = gt[2]@output / torch.clamp(alignment.sum(dim=2).unsqueeze(2), min=1)\n",
        "        else:\n",
        "            alignment = grouping_matrix@permutation_matrix@duplication_matrix\n",
        "            output = grouping_matrix@output /  torch.clamp(alignment.sum(dim=2).unsqueeze(2), min=1)\n",
        "        #output = gt[2]@output if gt is not None else grouping_matrix@output\n",
        "        output = self.decoder(output.permute(1, 0, 2))\n",
        "        return output, (duplication_probs, duplication_matrix, permutation_matrix, grouping_probs, grouping_matrix)\n",
        "\n",
        "\n",
        "class CTCAligner(nn.Module):\n",
        "    def __init__(self, encoder_index_dim, decoder_index_dim, embedding_dim=256, \n",
        "                 heads=4, hidden_dim=256, layers=4, dropout = 0.3):\n",
        "        super().__init__()\n",
        "        self.pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(embedding_dim, heads, hidden_dim, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, layers)\n",
        "        self.encoder = nn.Embedding(encoder_index_dim, embedding_dim)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.decoder = CTCTransformerDecoder(decoder_index_dim, hidden_dim)\n",
        "        self.permute = PermutationModule(hidden_dim, hidden_dim, hidden_dim)\n",
        "        self.duplicate = LengthRegDuplicationModule(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x, mask, gt=None):\n",
        "        x = self.encoder(x) * math.sqrt(self.embedding_dim)\n",
        "        x = self.pos_encoder(x)\n",
        "        output = self.transformer_encoder(x, mask).permute(1, 0, 2)\n",
        "        duplication_matrix = self.duplicate(output)\n",
        "        # if gt is not None:\n",
        "        #     print(gt[0].shape, output.shape)\n",
        "        output = gt[0]@output if gt is not None else self.pos_encoder(duplication_matrix@output)\n",
        "        permutation_matrix = self.permute(output)\n",
        "        if gt is not None:\n",
        "            output = gt[1]@output \n",
        "        else:\n",
        "            permutation_matrix = permutation_matrix.cpu().detach().numpy()\n",
        "            eye = np.eye(permutation_matrix.shape[1], permutation_matrix.shape[2])\n",
        "            for i in range(permutation_matrix.shape[0]):\n",
        "                try:\n",
        "                    permutation_matrix[i] += 1e-16\n",
        "                    xs, ys = linear_sum_assignment(-1 * np.log(permutation_matrix[i]))\n",
        "                    permutation_matrix[i] *= 0\n",
        "                    permutation_matrix[i, xs, ys] = 1\n",
        "                    ones = int(permutation_matrix[i].sum())\n",
        "                    permutation_matrix[i][ones:, ones:] = eye[ones:, ones:]\n",
        "                except Exception as e:\n",
        "                    permutation_matrix[i] = eye\n",
        "                    print(\"Warning: permutation_matrix \", e)\n",
        "            permutation_matrix = torch.Tensor(permutation_matrix).to(device=x.device)\n",
        "            output = permutation_matrix@output\n",
        "        output = self.decoder(output.permute(1, 0, 2))\n",
        "        return output, (duplication_matrix, permutation_matrix)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder_index_dim, decoder_index_dim, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(encoder_index_dim, hidden_dim=hidden_dim)\n",
        "        self.decoder = Decoder(decoder_index_dim, hidden_dim=hidden_dim)\n",
        "\n",
        "        self.encoder_index_dim = encoder_index_dim\n",
        "        self.decoder_index_dim = decoder_index_dim\n",
        "\n",
        "\n",
        "    def forward(self, x, y, use_teacher_forcing):\n",
        "        if y is not None:\n",
        "            assert x.device == y.device\n",
        "            assert x.shape[0] == y.shape[0]\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        device = x.device\n",
        "\n",
        "        if y is not None:\n",
        "            target_length = y.shape[1]\n",
        "        else:\n",
        "            target_length = x.shape[1]\n",
        "\n",
        "        enc_out, hidden = self.encoder(x)\n",
        "        out = x[:, 0].unsqueeze(1)\n",
        "\n",
        "        hidden = [hidden[0].view(self.encoder.layers, batch_size, -1).mean(dim=0).unsqueeze(0),\n",
        "                hidden[1].view(self.encoder.layers, batch_size, -1).mean(dim=0).unsqueeze(0)]\n",
        "\n",
        "        outputs = torch.zeros(batch_size, target_length, self.decoder_index_dim).to(device)\n",
        "        outputs[:, 0, 3] = 1 # SOS\n",
        "\n",
        "        if use_teacher_forcing and y is not None:\n",
        "            for di in range(1, target_length):\n",
        "                out, hidden = self.decoder(out.to(dtype=torch.long), hidden, enc_out)\n",
        "                outputs[:, di:di + 1] = out\n",
        "\n",
        "                out = y[:, di].unsqueeze(1)\n",
        "        else:\n",
        "            for di in range(1, target_length):\n",
        "                out, hidden = self.decoder(out.to(dtype=torch.long), hidden, enc_out)\n",
        "                outputs[:, di:di + 1] = out\n",
        "\n",
        "                out = out.argmax(dim=-1)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz, cuda=True):\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
        "    if cuda:\n",
        "        return mask.cuda()\n",
        "    return mask.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5OoH_GdBFUd0"
      },
      "outputs": [],
      "source": [
        "def decode_ctc(sent):\n",
        "    if not sent:\n",
        "        return sent\n",
        "    last_token = sent[0]\n",
        "    real_sent = []\n",
        "    for token in sent[1:]:\n",
        "        if last_token != '<CTC>' and token != last_token:\n",
        "            real_sent.append(last_token)\n",
        "        last_token = token\n",
        "    return real_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5icB5rlc9uRj"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model: nn.Module, train_loader, val_loader, tf=0.25, lr=3e-4, betas=(0.9, 0.999),\n",
        "                 project=\"ctc_translation\", name='ctc_model', save_every=None, save_path='./'):\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.model = model\n",
        "        self.save_path = save_path\n",
        "        self.save_every = save_every\n",
        "        self.name = name\n",
        "        self.project = project\n",
        "        self.tf = tf\n",
        "        wandb.init(project=project, name=name)\n",
        "        \n",
        "\n",
        "    def train_epoch(self, cuda=True, clip=1):\n",
        "        pass\n",
        "\n",
        "    def test_epoch(self, cuda=True):\n",
        "        pass\n",
        "\n",
        "    def output(self, cuda=True):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def log(epoch, train_loss, test_loss):\n",
        "        wandb.log({\n",
        "            'train': {\n",
        "                'loss': train_loss\n",
        "            },\n",
        "            'val': {\n",
        "                'loss': test_loss\n",
        "            },\n",
        "            'epoch': epoch\n",
        "        })\n",
        "\n",
        "    @staticmethod\n",
        "    def log_train(train_loss):\n",
        "        wandb.log({\n",
        "            'train': {\n",
        "                'loss': train_loss\n",
        "            }\n",
        "        })\n",
        "\n",
        "    @staticmethod\n",
        "    def log_test(test_loss):\n",
        "        wandb.log({\n",
        "            'test': {\n",
        "                'loss': test_loss\n",
        "            }\n",
        "        })\n",
        "\n",
        "    def checkpoint(self, epoch):\n",
        "        torch.save(self.model.state_dict(), os.path.join(self.save_path, self.name + str(epoch) + '.ckpt'))\n",
        "\n",
        "    def fit(self, max_epochs: int = 11, cuda=True, clip=1, log=False):\n",
        "        for epoch in range(max_epochs):\n",
        "            if self.save_every and epoch % self.save_every == 0:\n",
        "                self.checkpoint(epoch)\n",
        "            print('\\rEpoch: %d' % epoch)\n",
        "            self.output(cuda=cuda)\n",
        "            train_loss = self.train_epoch(cuda=cuda, clip=clip)\n",
        "            test_loss = self.test_epoch(cuda=cuda)\n",
        "            if log:\n",
        "                self.log(epoch, train_loss, test_loss)\n",
        "\n",
        "        if self.save_every:\n",
        "            self.checkpoint(max_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sScfru-OY-fz"
      },
      "outputs": [],
      "source": [
        "class TrLSTMTCTCrainer(Trainer):\n",
        "    def __init__(self, model: nn.Module, train_loader, val_loader, tf=0.25, lr=3e-4, betas=(0.9, 0.999),\n",
        "                 project=\"ctc_translation\", name='ctc_model', save_every=None, save_path='./'):\n",
        "        super().__init__(model, train_loader, val_loader, tf, lr, betas, project, name, save_every, save_path)\n",
        "        self.ctc_criterion = nn.CTCLoss(blank=vocabs[0].t2i['<CTC>'], zero_infinity=True)\n",
        "\n",
        "    def train_epoch(self, cuda=True, clip=1):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        total_ctc_loss = 0\n",
        "        for batch_idx, (tokens, targets, _) in enumerate(self.train_loader):\n",
        "            self.optimizer.zero_grad()\n",
        "            if cuda:\n",
        "                tokens = tokens.cuda()\n",
        "                targets = targets.cuda()\n",
        "            # input_lengths = torch.full(size=(tokens.shape[0],), \n",
        "            #                 fill_value=tokens.shape[1], \n",
        "            #                 dtype=torch.long)\n",
        "            target_lengths = (targets != 0).sum(dim=1)\n",
        "            ctc = self.model(tokens.to(dtype=torch.long), targets.to(dtype=torch.long))\n",
        "            input_lengths = (tokens != 0).sum(dim=1)\n",
        "            loss = 0\n",
        "            ctc_loss = self.ctc_criterion(ctc.permute(1, 0, 2).to(dtype=torch.float), targets.to(dtype=torch.long), \n",
        "                                          input_lengths=input_lengths, target_lengths=target_lengths)\n",
        "            total_ctc_loss += ctc_loss.item()\n",
        "            loss += ctc_loss\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), clip)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            self.log_train(total_loss / (batch_idx + 1))\n",
        "            print('\\rTrain loss: %4f, Batch: %d of %d' % (\n",
        "                total_loss / (batch_idx + 1), batch_idx + 1, len(self.train_loader)), end='')\n",
        "        print()\n",
        "        loss = total_loss / len(self.train_loader)\n",
        "        ctc_loss = total_ctc_loss / len(self.train_loader)\n",
        "        return loss\n",
        "\n",
        "    def test_epoch(self, cuda=True):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            total_loss = 0\n",
        "            total_ctc_loss = 0\n",
        "            for batch_idx, (tokens, targets, _) in enumerate(self.val_loader):\n",
        "                if cuda:\n",
        "                    tokens = tokens.cuda()\n",
        "                    targets = targets.cuda()\n",
        "                # input_lengths = torch.full(size=(tokens.shape[0],), \n",
        "                #                 fill_value=tokens.shape[1], \n",
        "                #                 dtype=torch.long)\n",
        "                target_lengths = (targets != 0).sum(dim=1)\n",
        "                ctc = self.model(tokens.to(dtype=torch.long), targets.to(dtype=torch.long))\n",
        "                input_lengths = (tokens != 0).sum(dim=1)\n",
        "\n",
        "                loss = 0 \n",
        "                ctc_loss = self.ctc_criterion(ctc.permute(1, 0, 2).to(dtype=torch.float), targets.to(dtype=torch.long), \n",
        "                                              input_lengths=input_lengths, target_lengths=target_lengths)\n",
        "                total_ctc_loss += ctc_loss.item()\n",
        "                loss += ctc_loss\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                self.log_test(total_loss / (batch_idx + 1))\n",
        "                print('\\rVal loss: %4f, Batch: %d of %d' % (\n",
        "                    total_loss / (batch_idx + 1), batch_idx + 1, len(self.val_loader)), end='')\n",
        "            print()\n",
        "            loss = total_loss / len(self.val_loader)\n",
        "            ctc_loss = total_ctc_loss / len(self.val_loader)\n",
        "            return loss\n",
        "\n",
        "    def output(self, cuda=True):\n",
        "        self.model.eval()\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        tokens, targets, _ = next(iter(self.val_loader))\n",
        "        tokens = tokens[1:2].to(dtype=torch.long)\n",
        "        targets = targets[1:2].to(dtype=torch.long)\n",
        "        batch_size = tokens.shape[0]\n",
        "        if cuda:\n",
        "            tokens = tokens.cuda()\n",
        "            targets = targets.cuda()\n",
        "        ctc = self.model(tokens, targets)\n",
        "        ctc = ctc.argmax(dim=-1)\n",
        "        summ = '<SOS>'\n",
        "        ctc_sent = []\n",
        "        for di in range(1, targets.shape[1]):\n",
        "            summ += vocabs[1].i2t[targets[0, di].cpu().detach().squeeze().item()] + ' '\n",
        "        for di in range(ctc.shape[1]):\n",
        "            ctc_sent.append(vocabs[1].i2t[ctc[0, di].cpu().detach().squeeze().item()])\n",
        "\n",
        "        print(summ[:-1])\n",
        "        print(' '.join(decode_ctc(ctc_sent)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D2DsSHY1vBcE"
      },
      "outputs": [],
      "source": [
        "class TrTransformerCTCrainer(Trainer):\n",
        "    def __init__(self, model: nn.Module, train_loader, val_loader, tf=0.25, lr=3e-4, betas=(0.9, 0.999),\n",
        "                 project=\"ctc_translation\", name='ctc_model', save_every=None, save_path='./'):\n",
        "        super().__init__(model, train_loader, val_loader, tf, lr, betas, project, name, save_every, save_path)\n",
        "        self.ctc_criterion = nn.CTCLoss(blank=vocabs[0].t2i['<CTC>'], zero_infinity=True)\n",
        "\n",
        "    def train_epoch(self, cuda=True, clip=1):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        total_ctc_loss = 0\n",
        "        for batch_idx, (tokens, targets, _) in enumerate(self.train_loader):\n",
        "            self.optimizer.zero_grad()\n",
        "            if cuda:\n",
        "                tokens = tokens.cuda()\n",
        "                targets = targets.cuda()\n",
        "            # input_lengths = torch.full(size=(tokens.shape[0],), \n",
        "            #                            fill_value=tokens.shape[1], \n",
        "            #                            dtype=torch.long)\n",
        "            target_lengths = (targets != 0).sum(dim=1)\n",
        "            ctc = self.model(tokens.to(dtype=torch.long).permute(1, 0), \n",
        "                             generate_square_subsequent_mask(tokens.shape[1], cuda))\n",
        "            input_lengths = (tokens != 0).sum(dim=1)\n",
        "            loss = 0\n",
        "            ctc_loss = self.ctc_criterion(ctc.permute(1, 0, 2).to(dtype=torch.float), targets.to(dtype=torch.long), \n",
        "                                          input_lengths=input_lengths, target_lengths=target_lengths)\n",
        "            total_ctc_loss += ctc_loss.item()\n",
        "            loss += ctc_loss\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), clip)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            self.log_train(total_loss / (batch_idx + 1))\n",
        "            print('\\rTrain loss: %4f, Batch: %d of %d' % (\n",
        "                total_loss / (batch_idx + 1), batch_idx + 1, len(self.train_loader)), end='')\n",
        "        print()\n",
        "        loss = total_loss / len(self.train_loader)\n",
        "        ctc_loss = total_ctc_loss / len(self.train_loader)\n",
        "        return loss\n",
        "\n",
        "    def test_epoch(self, cuda=True):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            total_loss = 0\n",
        "            total_ctc_loss = 0\n",
        "            for batch_idx, (tokens, targets, _) in enumerate(self.val_loader):\n",
        "                if cuda:\n",
        "                    tokens = tokens.cuda()\n",
        "                    targets = targets.cuda()\n",
        "                # input_lengths = torch.full(size=(tokens.shape[0],), \n",
        "                #                            fill_value=tokens.shape[1], \n",
        "                #                            dtype=torch.long)\n",
        "                target_lengths = (targets != 0).sum(dim=1)\n",
        "                ctc = self.model(tokens.to(dtype=torch.long).permute(1, 0), \n",
        "                                 generate_square_subsequent_mask(tokens.shape[1], cuda))\n",
        "                input_lengths = (tokens != 0).sum(dim=1)\n",
        "\n",
        "                loss = 0 \n",
        "                ctc_loss = self.ctc_criterion(ctc.permute(1, 0, 2).to(dtype=torch.float), targets.to(dtype=torch.long), \n",
        "                                              input_lengths=input_lengths, target_lengths=target_lengths)\n",
        "                total_ctc_loss += ctc_loss.item()\n",
        "                loss += ctc_loss\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                self.log_test(total_loss / (batch_idx + 1))\n",
        "                print('\\rVal loss: %4f, Batch: %d of %d' % (\n",
        "                    total_loss / (batch_idx + 1), batch_idx + 1, len(self.val_loader)), end='')\n",
        "            print()\n",
        "            loss = total_loss / len(self.val_loader)\n",
        "            ctc_loss = total_ctc_loss / len(self.val_loader)\n",
        "            return loss\n",
        "\n",
        "    def output(self, cuda=True):\n",
        "        self.model.eval()\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        tokens, targets, _ = next(iter(self.val_loader))\n",
        "        tokens = tokens[1:2].to(dtype=torch.long)\n",
        "        targets = targets[1:2].to(dtype=torch.long)\n",
        "        batch_size = tokens.shape[0]\n",
        "        if cuda:\n",
        "            tokens = tokens.cuda()\n",
        "            targets = targets.cuda()\n",
        "        ctc = self.model(tokens.permute(1, 0), \n",
        "                         generate_square_subsequent_mask(tokens.shape[1], cuda))\n",
        "        ctc = ctc.argmax(dim=-1)\n",
        "        summ = '<SOS>'\n",
        "        ctc_sent = []\n",
        "        for di in range(1, targets.shape[1]):\n",
        "            summ += vocabs[1].i2t[targets[0, di].cpu().detach().squeeze().item()] + ' '\n",
        "        for di in range(ctc.shape[1]):\n",
        "            ctc_sent.append(vocabs[1].i2t[ctc[0, di].cpu().detach().squeeze().item()])\n",
        "\n",
        "        print(summ[:-1])\n",
        "        print(' '.join(decode_ctc(ctc_sent)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9JyFF3sWfgRF"
      },
      "outputs": [],
      "source": [
        "def decompose_alignments(alignments, cuda=True):\n",
        "    groups = torch.cumsum(alignments.sum(2), 1).unsqueeze(2)\n",
        "    lengths = torch.cumsum(torch.clamp(alignments.sum(1), 0, 3), 1).unsqueeze(1)\n",
        "\n",
        "    grouping_matrix = torch.zeros((alignments.shape[0], alignments.shape[1], alignments.shape[1] * 3)) + torch.arange(1, 1 + alignments.shape[1] * 3).unsqueeze(0).unsqueeze(1)\n",
        "    if cuda:\n",
        "        grouping_matrix = grouping_matrix.cuda()\n",
        "    grouping_matrix[:, 0, :] = torch.clamp(groups[:, 0, :] - grouping_matrix[:, 0, :] + 1, 0, 1)\n",
        "    grouping_matrix[:, 1:, :] = torch.clamp(groups[:, 1:, :] - grouping_matrix[:, 1:, :] + 1, 0, 1) * torch.clamp(grouping_matrix[:, 1:, :] - groups[:, :-1, :], 0, 1)\n",
        "\n",
        "    duplication_matrix = torch.zeros((alignments.shape[0], alignments.shape[1] * 3, alignments.shape[2])) + torch.arange(1, 1 + alignments.shape[1] * 3).unsqueeze(0).unsqueeze(2)\n",
        "    if cuda:\n",
        "        duplication_matrix = duplication_matrix.cuda()\n",
        "    duplication_matrix[:, :, 0] = torch.clamp(lengths[:, :, 0] - duplication_matrix[:, :, 0] + 1, 0, 1)\n",
        "    duplication_matrix[:, :, 1:] = torch.clamp(lengths[:, :, 1:] - duplication_matrix[:, :, 1:] + 1, 0, 1) * torch.clamp(duplication_matrix[:, :, 1:] - lengths[:, :, :-1], 0, 1)\n",
        "    \n",
        "    permutation_matrix = (grouping_matrix.permute(0, 2, 1) / (alignments.sum(2).unsqueeze(1) + 1e-16))@alignments@(duplication_matrix.permute(0, 2, 1) / (alignments.sum(1).unsqueeze(2) + 1e-16))\n",
        "    eye = torch.eye(permutation_matrix.shape[1], permutation_matrix.shape[2])\n",
        "    if cuda:\n",
        "        eye = eye.cuda()\n",
        "\n",
        "    for i in range(permutation_matrix.shape[0]):\n",
        "        x = int(permutation_matrix[i].sum())\n",
        "        permutation_matrix[i][x:, x:] = eye[x:, x:]\n",
        "\n",
        "    return duplication_matrix, permutation_matrix, grouping_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0x3Yy_kP6aeW"
      },
      "outputs": [],
      "source": [
        "class AligNARTrainer(Trainer):\n",
        "    def __init__(self, model: nn.Module, train_loader, val_loader, tf=0.25, lr=3e-4, betas=(0.9, 0.999),\n",
        "                 project=\"ctc_translation\", name='ctc_model', save_every=None, save_path='./', lmbda=0.5):\n",
        "        super().__init__(model, train_loader, val_loader, tf, lr, betas, project, name, save_every, save_path)\n",
        "        self.lmbda = lmbda\n",
        "        self.groups_loss = GroupsLoss()\n",
        "        self.permutation_loss = nn.KLDivLoss(reduction=\"mean\")\n",
        "        self.cross_enthropy = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_epoch(self, cuda=True, clip=1):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        self.model.train()\n",
        "        total_grouping_loss = 0\n",
        "        total_permutation_loss = 0\n",
        "        total_duplication_loss = 0\n",
        "        total_ce_loss = 0\n",
        "        total_loss = 0\n",
        "        for batch_idx, (tokens, targets, alignments) in enumerate(self.train_loader):\n",
        "            self.optimizer.zero_grad()\n",
        "            if cuda:\n",
        "                tokens = tokens.cuda()\n",
        "                targets = targets.cuda()\n",
        "                alignments = alignments.cuda()\n",
        "\n",
        "            duplication_matrix, permutation_matrix, grouping_matrix = decompose_alignments(alignments, cuda=cuda)\n",
        "            \n",
        "            output, (duplication_probs, duplication_matrix_p, permutation_matrix_p, grouping_probs, grouping_matrix_p) = self.model(tokens.to(dtype=torch.long).permute(1, 0), \n",
        "                                                                                                                                    generate_square_subsequent_mask(tokens.shape[1], cuda),\n",
        "                                                                                                                                    [duplication_matrix.to(dtype=torch.float),\n",
        "                                                                                                                                     permutation_matrix.to(dtype=torch.float), \n",
        "                                                                                                                                     grouping_matrix.to(dtype=torch.float)])\n",
        "\n",
        "            duplication_loss = self.groups_loss(duplication_probs).mean()\n",
        "            permutation_loss = self.permutation_loss(torch.nn.functional.log_softmax(permutation_matrix_p, dim=-1), \n",
        "                                                     permutation_matrix).mean()\n",
        "            grouping_loss = self.groups_loss(grouping_probs).mean()\n",
        "            ce_loss = self.cross_enthropy(output.permute(0, 2, 1), targets).mean()\n",
        "\n",
        "\n",
        "            loss = ce_loss + self.lmbda * (duplication_loss + permutation_loss + grouping_loss)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), clip)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_grouping_loss += grouping_loss.item()\n",
        "            total_permutation_loss += permutation_loss.item()\n",
        "            total_duplication_loss += duplication_loss.item()\n",
        "            total_ce_loss += ce_loss.item()\n",
        "\n",
        "            self.log_train(total_loss / (batch_idx + 1), \n",
        "                           total_duplication_loss / (batch_idx + 1), \n",
        "                           total_permutation_loss / (batch_idx + 1),\n",
        "                           total_grouping_loss / (batch_idx + 1),\n",
        "                           total_ce_loss / (batch_idx + 1))\n",
        "            print('\\rTrain loss: %4f, Batch: %d of %d' % (\n",
        "                total_loss / (batch_idx + 1), batch_idx + 1, len(self.train_loader)), end='')\n",
        "        print()\n",
        "        loss = [total_loss / len(self.train_loader), \n",
        "                total_duplication_loss / len(self.train_loader), \n",
        "                total_permutation_loss / len(self.train_loader), \n",
        "                total_grouping_loss / len(self.train_loader), \n",
        "                total_ce_loss / len(self.train_loader)]\n",
        "        return loss\n",
        "\n",
        "    def test_epoch(self, cuda=True):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            total_grouping_loss = 0\n",
        "            total_permutation_loss = 0\n",
        "            total_duplication_loss = 0\n",
        "            total_ce_loss = 0\n",
        "            total_loss = 0\n",
        "            for batch_idx, (tokens, targets, alignments) in enumerate(self.val_loader):\n",
        "                if cuda:\n",
        "                    tokens = tokens.cuda()\n",
        "                    targets = targets.cuda()\n",
        "                    alignments = alignments.cuda()\n",
        "\n",
        "                targets = targets.repeat(1, 3)\n",
        "                targets[:, targets.shape[1] // 3:] = 0\n",
        "\n",
        "                duplication_matrix, permutation_matrix, grouping_matrix = decompose_alignments(alignments, cuda=cuda)\n",
        "\n",
        "                output, (duplication_probs, duplication_matrix_p, permutation_matrix_p, grouping_probs, grouping_matrix_p) = self.model(tokens.to(dtype=torch.long).permute(1, 0), \n",
        "                                                                                                                                        generate_square_subsequent_mask(tokens.shape[1], cuda))\n",
        "\n",
        "                duplication_loss = self.groups_loss(duplication_probs).mean()\n",
        "                permutation_loss = self.permutation_loss(torch.nn.functional.log_softmax(permutation_matrix_p, dim=-1), \n",
        "                                                         permutation_matrix).mean()\n",
        "                grouping_loss = self.groups_loss(grouping_probs).mean()\n",
        "                ce_loss = self.cross_enthropy(output.permute(0, 2, 1), targets).mean()\n",
        "                \n",
        "                loss = ce_loss + self.lmbda * (duplication_loss + permutation_loss + grouping_loss)\n",
        "                total_loss += loss.item()\n",
        "                total_grouping_loss += grouping_loss.item()\n",
        "                total_permutation_loss += permutation_loss.item()\n",
        "                total_duplication_loss += duplication_loss.item()\n",
        "                total_ce_loss += ce_loss.item()\n",
        "\n",
        "                self.log_test(total_loss / (batch_idx + 1), \n",
        "                              total_duplication_loss / (batch_idx + 1), \n",
        "                              total_permutation_loss / (batch_idx + 1),\n",
        "                              total_grouping_loss / (batch_idx + 1),\n",
        "                              total_ce_loss / (batch_idx + 1))\n",
        "                print('\\rVal loss: %4f, Batch: %d of %d' % (\n",
        "                    total_loss / (batch_idx + 1), batch_idx + 1, len(self.val_loader)), end='')\n",
        "            print()\n",
        "            loss = [total_loss / len(self.val_loader), \n",
        "                    total_duplication_loss / len(self.val_loader), \n",
        "                    total_permutation_loss / len(self.val_loader), \n",
        "                    total_grouping_loss / len(self.val_loader), \n",
        "                    total_ce_loss / len(self.val_loader)]\n",
        "            return loss\n",
        "\n",
        "    def output(self, cuda=True):\n",
        "        self.model.eval()\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        tokens, targets, alignments = next(iter(self.val_loader))\n",
        "        tokens = tokens[1:2].to(dtype=torch.long)\n",
        "        targets = targets[1:2].to(dtype=torch.long)\n",
        "        batch_size = tokens.shape[0]\n",
        "        if cuda:\n",
        "            tokens = tokens.cuda()\n",
        "            targets = targets.cuda()\n",
        "        output, _ = self.model(tokens.to(dtype=torch.long).permute(1, 0),\n",
        "                               generate_square_subsequent_mask(tokens.shape[1], cuda))\n",
        "        output = output.argmax(dim=-1)\n",
        "        \n",
        "        summ = '<SOS>'\n",
        "        sent = []\n",
        "        for di in range(1, targets.shape[1]):\n",
        "            summ += vocabs[1].i2t[targets[0, di].cpu().detach().squeeze().item()] + ' '\n",
        "        for di in range(output.shape[1]):\n",
        "            sent.append(vocabs[1].i2t[output[0, di].cpu().detach().squeeze().item()])\n",
        "\n",
        "        print(summ[:-1])\n",
        "        print(' '.join(sent))\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def log(epoch, train_loss, test_loss):\n",
        "        wandb.log({\n",
        "            'train': {\n",
        "                'loss': train_loss[0],\n",
        "                'duplication_loss': train_loss[1],\n",
        "                'permutation_loss': train_loss[2],\n",
        "                'grouping_loss': train_loss[3],\n",
        "                'cross_enthropy_loss': train_loss[4]\n",
        "            },\n",
        "            'val': {\n",
        "                'loss': test_loss[0],\n",
        "                'duplication_loss': test_loss[1],\n",
        "                'permutation_loss': test_loss[2],\n",
        "                'grouping_loss': test_loss[3],\n",
        "                'cross_enthropy_loss': test_loss[4]\n",
        "            },\n",
        "            'epoch': epoch\n",
        "        })\n",
        "\n",
        "    @staticmethod\n",
        "    def log_train(train_loss, duplication_loss, permutation_loss, grouping_loss, ce_loss):\n",
        "        wandb.log({\n",
        "            'train': {\n",
        "                'loss': train_loss,\n",
        "                'duplication_loss': duplication_loss,\n",
        "                'permutation_loss': permutation_loss,\n",
        "                'grouping_loss': grouping_loss,\n",
        "                'cross_enthropy_loss': ce_loss\n",
        "            }\n",
        "        })\n",
        "\n",
        "    @staticmethod\n",
        "    def log_test(test_loss, duplication_loss, permutation_loss, grouping_loss, ce_loss):\n",
        "        wandb.log({\n",
        "            'test': {\n",
        "                'loss': test_loss,\n",
        "                'duplication_loss': duplication_loss,\n",
        "                'permutation_loss': permutation_loss,\n",
        "                'grouping_loss': grouping_loss,\n",
        "                'cross_enthropy_loss': ce_loss\n",
        "            }\n",
        "        })\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hjcXBV69gYDg"
      },
      "outputs": [],
      "source": [
        "class CTCAligNARTrainer(Trainer):\n",
        "    def __init__(self, model: nn.Module, train_loader, val_loader, tf=0.25, lr=3e-4, betas=(0.9, 0.999),\n",
        "                 project=\"ctc_translation\", name='ctc_model', save_every=None, save_path='./', lmbda=0.5):\n",
        "        super().__init__(model, train_loader, val_loader, tf, lr, betas, project, name, save_every, save_path)\n",
        "        self.lmbda = lmbda\n",
        "        self.groups_loss = GroupsLoss()\n",
        "        self.permutation_loss = nn.KLDivLoss(reduction=\"mean\")\n",
        "        self.ctc_criterion = nn.CTCLoss(blank=vocabs[0].t2i['<CTC>'], zero_infinity=True)\n",
        "\n",
        "    def train_epoch(self, cuda=True, clip=1):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        total_permutation_loss = 0\n",
        "        total_ctc_loss = 0\n",
        "        for batch_idx, (tokens, targets, alignments) in enumerate(self.train_loader):\n",
        "            self.optimizer.zero_grad()\n",
        "            if cuda:\n",
        "                tokens = tokens.cuda()\n",
        "                targets = targets.cuda()\n",
        "                alignments = alignments.cuda()\n",
        "            # input_lengths = torch.full(size=(tokens.shape[0],), \n",
        "            #                            fill_value=tokens.shape[1], \n",
        "            #                            dtype=torch.long)\n",
        "            target_lengths = (targets != 0).sum(dim=1)\n",
        "\n",
        "            duplication_matrix, permutation_matrix, grouping_matrix = decompose_alignments(alignments, cuda=cuda)\n",
        "\n",
        "\n",
        "            ctc, (duplication_matrix_p, permutation_matrix_p) = self.model(tokens.to(dtype=torch.long).permute(1, 0), \n",
        "                                                                       generate_square_subsequent_mask(tokens.shape[1], cuda),\n",
        "                                                                        [duplication_matrix.to(dtype=torch.float), permutation_matrix.to(dtype=torch.float)])\n",
        "            input_lengths = (tokens != 0).sum(dim=1)\n",
        "            loss = 0\n",
        "            ctc_loss = self.ctc_criterion(ctc.permute(1, 0, 2).to(dtype=torch.float), targets.to(dtype=torch.long), \n",
        "                                          input_lengths=input_lengths, target_lengths=target_lengths)\n",
        "            permutation_loss = self.permutation_loss(torch.nn.functional.log_softmax(permutation_matrix_p, dim=-1),\n",
        "                                                     permutation_matrix).mean()\n",
        "            loss += ctc_loss + permutation_loss\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), clip)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_ctc_loss += ctc_loss.item()\n",
        "            total_permutation_loss += permutation_loss.item()\n",
        "\n",
        "            self.log_train(total_loss / (batch_idx + 1), \n",
        "                           total_permutation_loss / (batch_idx + 1), \n",
        "                           total_ctc_loss / (batch_idx + 1))\n",
        "            print('\\rTrain loss: %4f, Batch: %d of %d' % (\n",
        "                total_loss / (batch_idx + 1), batch_idx + 1, len(self.train_loader)), end='')\n",
        "        print()\n",
        "        loss = [total_loss / len(self.train_loader),\n",
        "                total_permutation_loss / len(self.train_loader),\n",
        "                total_ctc_loss / len(self.train_loader)]\n",
        "        return loss\n",
        "\n",
        "    def test_epoch(self, cuda=True):\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            total_loss = 0\n",
        "            total_permutation_loss = 0\n",
        "            total_ctc_loss = 0\n",
        "            for batch_idx, (tokens, targets, alignments) in enumerate(self.val_loader):\n",
        "                if cuda:\n",
        "                    tokens = tokens.cuda()\n",
        "                    targets = targets.cuda()\n",
        "                    alignments = alignments.cuda()\n",
        "                # input_lengths = torch.full(size=(tokens.shape[0],), \n",
        "                #                            fill_value=tokens.shape[1], \n",
        "                #                            dtype=torch.long)\n",
        "                target_lengths = (targets != 0).sum(dim=1)\n",
        "                targets = targets.repeat(1, 3)\n",
        "                targets[:, targets.shape[1] // 3:] = 0\n",
        "\n",
        "                duplication_matrix, permutation_matrix, grouping_matrix = decompose_alignments(alignments, cuda=cuda)\n",
        "\n",
        "                ctc, (duplication_matrix_p, permutation_matrix_p) = self.model(tokens.to(dtype=torch.long).permute(1, 0), \n",
        "                                                                               generate_square_subsequent_mask(tokens.shape[1], cuda))\n",
        "                input_lengths = (tokens != 0).sum(dim=1)\n",
        "\n",
        "                loss = 0 \n",
        "                ctc_loss = self.ctc_criterion(ctc.permute(1, 0, 2).to(dtype=torch.float), targets.to(dtype=torch.long), \n",
        "                                              input_lengths=input_lengths, target_lengths=target_lengths)\n",
        "                permutation_loss = self.permutation_loss(torch.nn.functional.log_softmax(permutation_matrix_p, dim=-1),\n",
        "                                                         permutation_matrix).mean()\n",
        "                loss += ctc_loss + permutation_loss\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_ctc_loss += ctc_loss.item()\n",
        "                total_permutation_loss += permutation_loss.item()\n",
        "            \n",
        "                self.log_test(total_loss / (batch_idx + 1), \n",
        "                              total_permutation_loss / (batch_idx + 1), \n",
        "                              total_ctc_loss / (batch_idx + 1))\n",
        "                print('\\rVal loss: %4f, Batch: %d of %d' % (\n",
        "                    total_loss / (batch_idx + 1), batch_idx + 1, len(self.val_loader)), end='')\n",
        "            print()\n",
        "            loss = [total_loss / len(self.val_loader),\n",
        "                    total_permutation_loss / len(self.val_loader),\n",
        "                    total_ctc_loss / len(self.val_loader)]\n",
        "            return loss\n",
        "\n",
        "    def output(self, cuda=True):\n",
        "        self.model.eval()\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        tokens, targets, _ = next(iter(self.val_loader))\n",
        "        tokens = tokens[1:2].to(dtype=torch.long)\n",
        "        targets = targets[1:2].to(dtype=torch.long)\n",
        "        batch_size = tokens.shape[0]\n",
        "        if cuda:\n",
        "            tokens = tokens.cuda()\n",
        "            targets = targets.cuda()\n",
        "        ctc, _ = self.model(tokens.permute(1, 0), \n",
        "                         generate_square_subsequent_mask(tokens.shape[1], cuda))\n",
        "        ctc = ctc.argmax(dim=-1)\n",
        "        summ = '<SOS>'\n",
        "        ctc_sent = []\n",
        "        for di in range(1, targets.shape[1]):\n",
        "            summ += vocabs[1].i2t[targets[0, di].cpu().detach().squeeze().item()] + ' '\n",
        "        for di in range(ctc.shape[1]):\n",
        "            ctc_sent.append(vocabs[1].i2t[ctc[0, di].cpu().detach().squeeze().item()])\n",
        "\n",
        "        print(summ[:-1])\n",
        "        print(' '.join(decode_ctc(ctc_sent)))\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def log(epoch, train_loss, test_loss):\n",
        "        wandb.log({\n",
        "            'train': {\n",
        "                'loss': train_loss[0],\n",
        "                'permutation_loss': train_loss[1],\n",
        "                'ctc_loss': train_loss[2]\n",
        "            },\n",
        "            'val': {\n",
        "                'loss': test_loss[0],\n",
        "                'permutation_loss': test_loss[1],\n",
        "                'ctc_loss': test_loss[2]\n",
        "            },\n",
        "            'epoch': epoch\n",
        "        })\n",
        "\n",
        "    @staticmethod\n",
        "    def log_train(train_loss, permutation_loss, ctc_loss):\n",
        "        wandb.log({\n",
        "            'train': {\n",
        "                'loss': train_loss,\n",
        "                'permutation_loss': permutation_loss,\n",
        "                'ctc_loss': ctc_loss\n",
        "            }\n",
        "        })\n",
        "\n",
        "    @staticmethod\n",
        "    def log_test(test_loss, permutation_loss, ctc_loss):\n",
        "        wandb.log({\n",
        "            'test': {\n",
        "                'loss': test_loss,\n",
        "                'permutation_loss': permutation_loss,\n",
        "                'ctc_loss': ctc_loss\n",
        "            }\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrBiLSTMTrainer(Trainer):\n",
        "     def __init__(self, model: nn.Module, train_loader, val_loader, tf=0.5, lr=3e-4, betas=(0.9, 0.999),\n",
        "                  project=\"ctc_translation\", name='ctc_model', save_every=None, save_path='./',):\n",
        "         super().__init__(model, train_loader, val_loader, tf, lr, betas, project, name, save_every, save_path)\n",
        "         self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "     def train_epoch(self, cuda=True, clip=1):\n",
        "         if cuda:\n",
        "             self.model.cuda()\n",
        "         else:\n",
        "             self.model.cpu()\n",
        "         self.model.train()\n",
        "         total_loss = 0\n",
        "\n",
        "         for batch_idx, (tokens, targets, _) in enumerate(self.train_loader):\n",
        "             self.optimizer.zero_grad()\n",
        "             if cuda:\n",
        "                 tokens = tokens.cuda()\n",
        "                 targets = targets.cuda()\n",
        "             use_teacher_forcing = True if random.random() < self.tf else False\n",
        "             outputs = self.model(tokens.to(dtype=torch.long), \n",
        "                                  targets.to(dtype=torch.long), use_teacher_forcing)\n",
        "\n",
        "             loss = self.criterion(outputs[:, 1:].reshape(-1, self.model.decoder_index_dim),\n",
        "                                   targets[:, 1:].flatten())\n",
        "             loss.backward()\n",
        "             nn.utils.clip_grad_norm_(self.model.parameters(), clip)\n",
        "             self.optimizer.step()\n",
        "\n",
        "             total_loss += loss.item()\n",
        "\n",
        "             self.log_train(total_loss / (batch_idx + 1))\n",
        "             print('\\rTrain loss: %4f, Batch: %d of %d' % (total_loss / (batch_idx + 1), \n",
        "                                                           batch_idx + 1, len(self.train_loader)), end='')\n",
        "         print()\n",
        "         loss = total_loss / len(self.train_loader)\n",
        "         return loss\n",
        "\n",
        "     def test_epoch(self, cuda=True):\n",
        "         if cuda:\n",
        "             self.model.cuda()\n",
        "         else:\n",
        "             self.model.cpu()\n",
        "         with torch.no_grad():\n",
        "             self.model.eval()\n",
        "             total_loss = 0\n",
        "             for batch_idx, (tokens, targets, _) in enumerate(self.val_loader):\n",
        "                 if cuda:\n",
        "                     tokens = tokens.cuda()\n",
        "                     targets = targets.cuda()\n",
        "                 use_teacher_forcing = False\n",
        "                 outputs = self.model(tokens.to(dtype=torch.long), \n",
        "                                      targets.to(dtype=torch.long),\n",
        "                                      use_teacher_forcing)\n",
        "\n",
        "                 loss = self.criterion(outputs[:, 1:].reshape(-1, self.model.decoder_index_dim),\n",
        "                                       targets[:, 1:].flatten())\n",
        "                 total_loss += loss.item()\n",
        "\n",
        "                 self.log_test(total_loss / (batch_idx + 1))\n",
        "                 print('\\rVal loss: %4f, Batch: %d of %d' % (total_loss / (batch_idx + 1), \n",
        "                                                             batch_idx + 1, len(self.val_loader)), end='')\n",
        "             print()\n",
        "             loss = total_loss / len(self.val_loader)\n",
        "             return loss\n",
        "\n",
        "     def output(self, cuda=True):\n",
        "        self.model.eval()\n",
        "        if cuda:\n",
        "            self.model.cuda()\n",
        "        else:\n",
        "            self.model.cpu()\n",
        "        tokens, targets, _ = next(iter(self.val_loader))\n",
        "        tokens = tokens[1:2].to(dtype=torch.long)\n",
        "        targets = targets[1:2].to(dtype=torch.long)\n",
        "        batch_size = tokens.shape[0]\n",
        "        if cuda:\n",
        "            tokens = tokens.cuda()\n",
        "            targets = targets.cuda()\n",
        "        use_teacher_forcing = False\n",
        "        output = self.model(tokens, None, False)\n",
        "        output = output.argmax(dim=-1)\n",
        "        \n",
        "        summ = '<SOS>'\n",
        "        sent = []\n",
        "        for di in range(1, targets.shape[1]):\n",
        "            summ += vocabs[1].i2t[targets[0, di].cpu().detach().squeeze().item()] + ' '\n",
        "        for di in range(output.shape[1]):\n",
        "            sent.append(vocabs[1].i2t[output[0, di].cpu().detach().squeeze().item()])\n",
        "\n",
        "        print(summ[:-1])\n",
        "        print(' '.join(sent))"
      ],
      "metadata": {
        "id": "g83pmAd-0rXJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FrsXIR5Zvx",
        "outputId": "a2f98475-0072-4d9f-f8d5-053d8db6dcac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model = Seq2Seq(len(vocabs[0].t2i), len(vocabs[1].t2i))\n",
        "# ctc_only_model.load_state_dict(torch.load('/content/drive/MyDrive/CTC_in_NLP/checkpoints/bilstm_ctc_only_25610.ckpt'))\n",
        "bilstm_trainer = TrBiLSTMTrainer(bilstm_model, train_loader, val_loader, \n",
        "                                  lr=3e-4, save_every=1, name='bilstm_de_en', \n",
        "                                  save_path=f'/content/drive/MyDrive/CTC_in_NLP/checkpoints')\n",
        "bilstm_trainer.fit(log=True, max_epochs=3)"
      ],
      "metadata": {
        "id": "HTCeNVkrc7s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhE35QVPftGM",
        "outputId": "85e0041f-8860-4da6-f38a-e75d7449e8db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "alignart_model = AligNART(len(vocabs[0].t2i), len(vocabs[1].t2i))\n",
        "alignart_model.load_state_dict(torch.load('/content/drive/MyDrive/CTC_in_NLP/checkpoints/alignart_256_de_en1.ckpt'))\n",
        "# alignart_trainer = AligNARTrainer(alignart_model, train_loader, val_loader, \n",
        "#                                   lr=3e-4, save_every=1, name='alignart_de_en', \n",
        "#                                   save_path=f'/content/drive/MyDrive/CTC_in_NLP/checkpoints')\n",
        "# alignart_trainer.fit(log=True, max_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un4meGvDdvqp",
        "outputId": "4d47bc3c-53a2-4b88-dce7-facc592da3ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "ctc_aligner_model = CTCAligner(len(vocabs[0].t2i), len(vocabs[1].t2i))\n",
        "ctc_aligner_model.load_state_dict(torch.load('/content/drive/MyDrive/CTC_in_NLP/checkpoints/ctc_aligner_256_de_en1.ckpt'))\n",
        "# ctc_aligner_trainer = CTCAligNARTrainer(ctc_aligner_model, train_loader, val_loader, \n",
        "#                                   lr=3e-4, save_every=1, name='ctc_aligner_256_de_en', \n",
        "#                                   save_path=f'/content/drive/MyDrive/CTC_in_NLP/checkpoints')\n",
        "# ctc_aligner_trainer.fit(log=True, max_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8cF4k0gCZMHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89795f85-1b7c-46c8-e94d-c156dc3fe004"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "ctc_only_model = Seq2CTC(len(vocabs[0].t2i), len(vocabs[1].t2i))\n",
        "ctc_only_model.load_state_dict(torch.load('/content/drive/MyDrive/CTC_in_NLP/checkpoints/bilstm_ctc_only_256_de_en4.ckpt'))\n",
        "# ctc_only_trainer = TrLSTMTCTCrainer(ctc_only_model, train_loader, val_loader, \n",
        "#                                   lr=3e-4, save_every=1, name='bilstm_ctc_only_256_de_en', \n",
        "#                                   save_path=f'/content/drive/MyDrive/CTC_in_NLP/checkpoints')\n",
        "# ctc_only_trainer.fit(log=True, max_epochs=5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66nkb4t1tF1_",
        "outputId": "fa52d959-7f55-4aa5-fea5-2fd4c2874979"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "ctc_only_transformer_model = Transformer2CTC(len(vocabs[0].t2i), len(vocabs[1].t2i))\n",
        "# encoder_index_dim, decoder_index_dim, heads, hidden_dim, layers\n",
        "ctc_only_transformer_model.load_state_dict(torch.load('/content/drive/MyDrive/CTC_in_NLP/checkpoints/transformer_ctc_only_de_en4.ckpt'))\n",
        "# ctc_only_trainer = TrTransformerCTCrainer(ctc_only_transformer_model, train_loader, val_loader, \n",
        "#                                   lr=3e-4, save_every=1, name='transformer_ctc_only_de_en', \n",
        "#                                   save_path=f'/content/drive/MyDrive/CTC_in_NLP/checkpoints')\n",
        "# ctc_only_trainer.fit(log=True, max_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeuA_HMa_wKo",
        "outputId": "0e0c2def-a9e8-409d-f976-3abe6c5f6d43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "ctc_only_t2t_model = Transformer2TransformerCTC(len(vocabs[0].t2i), len(vocabs[1].t2i))\n",
        "# encoder_index_dim, decoder_index_dim, heads, hidden_dim, layers\n",
        "ctc_only_t2t_model.load_state_dict(torch.load('/content/drive/MyDrive/CTC_in_NLP/checkpoints/transformer2transformer_ctc_only_de_en5.ckpt'))\n",
        "# ctc_only_trainer = TrTransformerCTCrainer(ctc_only_t2t_model, train_loader, val_loader, \n",
        "#                                   lr=3e-4, save_every=1, name='transformer2transformer_ctc_only_de_en', \n",
        "#                                   save_path=f'/content/drive/MyDrive/CTC_in_NLP/checkpoints')\n",
        "# ctc_only_trainer.fit(log=True, max_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "CTcX_QNSGH7n"
      },
      "outputs": [],
      "source": [
        "def cut_on_eos(tokens_iter):\n",
        "    for token in tokens_iter:\n",
        "        if token == '<EOS>':\n",
        "            break\n",
        "        yield token\n",
        "\n",
        "def remove_tech_tokens(tokens_iter, tokens_to_remove=['<SOS>', '<UNK>', '<PAD>']):\n",
        "    return [x for x in tokens_iter if x not in tokens_to_remove]\n",
        "\n",
        "def generate_translation(src, trg, model):\n",
        "    model.eval()\n",
        "\n",
        "    ctc = model(src, trg)\n",
        "    output = ctc[:, 1:].argmax(-1)\n",
        "\n",
        "    source = remove_tech_tokens(cut_on_eos([vocabs[0].i2t[x] for x in list(src[0, :].cpu().detach().numpy())]))\n",
        "    original = remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(trg[0, :].cpu().detach().numpy())]))\n",
        "    generated = decode_ctc(remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(output[0, :].cpu().detach().squeeze().numpy())])))\n",
        "    \n",
        "    print('Source: {}'.format(' '.join(source)))\n",
        "    print('Original: {}'.format(' '.join(original)))\n",
        "    print('Generated: {}'.format(' '.join(generated)))\n",
        "    print()\n",
        "\n",
        "def generate_trf_translation(src, trg, model):\n",
        "    model.eval()\n",
        "\n",
        "    ctc = model(src.permute(1, 0).cpu(), \n",
        "                generate_square_subsequent_mask(src.shape[1], False))\n",
        "    output = ctc[:, 1:].argmax(-1)\n",
        "\n",
        "    source = remove_tech_tokens(cut_on_eos([vocabs[0].i2t[x] for x in list(src[0, :].cpu().detach().numpy())]))\n",
        "    original = remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(trg[0, :].cpu().detach().numpy())]))\n",
        "    generated = decode_ctc(remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(output[0, :].cpu().detach().squeeze().numpy())])))\n",
        "    \n",
        "    print('Source: {}'.format(' '.join(source)))\n",
        "    print('Original: {}'.format(' '.join(original)))\n",
        "    print('Generated: {}'.format(' '.join(generated)))\n",
        "    print()\n",
        "\n",
        "def generate_trf_align_translation(src, trg, model):\n",
        "    model.eval()\n",
        "\n",
        "    ctc, _ = model(src.permute(1, 0).cpu(), \n",
        "                generate_square_subsequent_mask(src.shape[1], False))\n",
        "    output = ctc[:, 1:].argmax(-1)\n",
        "\n",
        "    source = remove_tech_tokens(cut_on_eos([vocabs[0].i2t[x] for x in list(src[0, :].cpu().detach().numpy())]))\n",
        "    original = remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(trg[0, :].cpu().detach().numpy())]))\n",
        "    generated = decode_ctc(remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(output[0, :].cpu().detach().squeeze().numpy())])))\n",
        "    \n",
        "    print('Source: {}'.format(' '.join(source)))\n",
        "    print('Original: {}'.format(' '.join(original)))\n",
        "    print('Generated: {}'.format(' '.join(generated)))\n",
        "    print()\n",
        "\n",
        "def generate_trf_alignart_translation(src, trg, model):\n",
        "    model.eval()\n",
        "\n",
        "    ctc, _ = model(src.permute(1, 0).cpu(), \n",
        "                generate_square_subsequent_mask(src.shape[1], False))\n",
        "    output = ctc[:, 1:].argmax(-1)\n",
        "\n",
        "    source = remove_tech_tokens(cut_on_eos([vocabs[0].i2t[x] for x in list(src[0, :].cpu().detach().numpy())]))\n",
        "    original = remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(trg[0, :].cpu().detach().numpy())]))\n",
        "    generated = remove_tech_tokens(cut_on_eos([vocabs[1].i2t[x] for x in list(output[0, :].cpu().detach().squeeze().numpy())]))\n",
        "    \n",
        "    print('Source: {}'.format(' '.join(source)))\n",
        "    print('Original: {}'.format(' '.join(original)))\n",
        "    print('Generated: {}'.format(' '.join(generated)))\n",
        "    print()\n",
        "\n",
        "def get_text(x):\n",
        "     generated = remove_tech_tokens(cut_on_eos([vocabs[1].i2t[elem] for elem in list(x)]))\n",
        "     return generated\n",
        "\n",
        "\n",
        "def calculate_ctc_bleu(model, loader):\n",
        "    model.eval()\n",
        "    generated = []\n",
        "    original = []\n",
        "    for src, trg, _ in loader:\n",
        "        ctc = model(src.cuda(), trg.cuda())\n",
        "        output = ctc[:, 1:].argmax(-1)\n",
        "\n",
        "        original.extend([decode_ctc(get_text(x)) for x in trg.cpu().numpy()])\n",
        "        generated.extend([decode_ctc(get_text(x)) for x in output.detach().cpu().squeeze().numpy()])\n",
        "    \n",
        "    return corpus_bleu([[text] for text in original], generated) * 100\n",
        "\n",
        "\n",
        "def calculate_aligner_bleu(model, loader):\n",
        "    model.eval()\n",
        "    generated = []\n",
        "    original = []\n",
        "    for src, trg, _ in loader:\n",
        "        output, _ = model(src.permute(1, 0).cuda(), \n",
        "                         generate_square_subsequent_mask(src.shape[1], True))\n",
        "        output = output[:, 1:].argmax(-1)\n",
        "\n",
        "        original.extend([get_text(x) for x in trg.cpu().numpy()])\n",
        "        generated.extend([get_text(x) for x in output.detach().cpu().squeeze().numpy()])\n",
        "    \n",
        "    return corpus_bleu([[text] for text in original], generated) * 100\n",
        "\n",
        "\n",
        "def calculate_ctc_aligner_bleu(model, loader):\n",
        "    model.eval()\n",
        "    generated = []\n",
        "    original = []\n",
        "    for src, trg, _ in loader:\n",
        "        output, _ = model(src.permute(1, 0).cuda(), \n",
        "                         generate_square_subsequent_mask(src.shape[1], True))\n",
        "        output = output[:, 1:].argmax(-1)\n",
        "\n",
        "        original.extend([decode_ctc(get_text(x)) for x in trg.cpu().numpy()])\n",
        "        generated.extend([decode_ctc(get_text(x)) for x in output.detach().cpu().squeeze().numpy()])\n",
        "    \n",
        "    return corpus_bleu([[text] for text in original], generated) * 100\n",
        "\n",
        "\n",
        "def calculate_ctc_trf_bleu(model, loader):\n",
        "    model.eval()\n",
        "    generated = []\n",
        "    original = []\n",
        "    for src, trg, _ in loader:\n",
        "        ctc = model(src.permute(1, 0).cuda(), \n",
        "                    generate_square_subsequent_mask(src.shape[1], True))\n",
        "        output = ctc[:, 1:].argmax(-1)\n",
        "\n",
        "        original.extend([decode_ctc(get_text(x)) for x in trg.cpu().numpy()])\n",
        "        generated.extend([decode_ctc(get_text(x)) for x in output.detach().cpu().squeeze().numpy()])\n",
        "    \n",
        "    return corpus_bleu([[text] for text in original], generated) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6r62S_xIWiI",
        "outputId": "4675f4da-c664-4ec2-b3ba-2a16ce4fd06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.88 s, sys: 27 ms, total: 1.9 s\n",
            "Wall time: 2.45 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.20995532654378"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "%%time\n",
        "calculate_ctc_bleu(ctc_only_model.cuda(), val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWjSDitxHE7B",
        "outputId": "aaf0f339-f305-4fc8-acb0-72370c18ff15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 939 ms, sys: 7.97 ms, total: 947 ms\n",
            "Wall time: 1.01 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.35489341856907"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "%%time\n",
        "calculate_ctc_trf_bleu(ctc_only_t2t_model.eval().cuda(), val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWn4Qpyp7zk3",
        "outputId": "6bd39297-3ddb-4cc4-ddda-40ad7285d15b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.05 s, sys: 1.89 ms, total: 1.06 s\n",
            "Wall time: 1.07 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.90116777002967"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "%%time\n",
        "calculate_ctc_trf_bleu(ctc_only_transformer_model.eval().cuda(), val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "calculate_aligner_bleu(alignart_model.eval().cuda(), val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQTVcaky7uxw",
        "outputId": "79296ca6-3829-485c-ac43-cae6f910b67d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.39 s, sys: 17 ms, total: 2.41 s\n",
            "Wall time: 2.51 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.84921190003277"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "calculate_ctc_aligner_bleu(ctc_aligner_model.eval().cuda(), val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZHyawv88MAw",
        "outputId": "2702cf7c-563d-46c0-c53f-28e56e1c1f75"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.28 s, sys: 21.9 ms, total: 2.3 s\n",
            "Wall time: 2.32 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.00497336772189"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "057043f95f9244f1af63816c77dbc79f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab40f6e365944e7a44542c558190cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b22ce93b28ba4ecabea756ee75641172",
              "IPY_MODEL_5f936c2664bb4dad96248ad245629c59",
              "IPY_MODEL_c377a4ba58db40d59985c538741ced61"
            ],
            "layout": "IPY_MODEL_17bf3e4281404f5cacc0b31874bccb24"
          }
        },
        "17bf3e4281404f5cacc0b31874bccb24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3572c0077348a881a005e01c4f448b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_539d4137c92a472e80ccf3025e7f550a",
              "IPY_MODEL_a1c2617188b64744a8c014202f75e9bf",
              "IPY_MODEL_553a93cf5a6e4d6195e86e9c84ba3adb"
            ],
            "layout": "IPY_MODEL_7e50feb0d118481e9b428e98d8a194ec"
          }
        },
        "279f11a561134e539e07b81eba1b20f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4091b85a534428d850c98fea1f24673",
            "placeholder": "​",
            "style": "IPY_MODEL_4ffae02276a8408fa78ae2829c16951c",
            "value": " 3239358/? [11:43&lt;00:00, 4558.27it/s]"
          }
        },
        "29660b40777a43ed84b8fdb0a0b04a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b6451eceb2e4a41be58dd3352f0f2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cd35d11eb624c5b8f2ecf88ad8203dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce36610875874f6487c7f29a6f394834",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b81ad2b34be74bfaa790757b5b64298f",
            "value": 1
          }
        },
        "2d45fb7c805a4436ac546ccb82076f75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6aabbff5cc4e2da3aead804acd3a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc4551c6a2d74c5cb064c5569100b119",
              "IPY_MODEL_852e77daec144f089d0662237831a046",
              "IPY_MODEL_279f11a561134e539e07b81eba1b20f6"
            ],
            "layout": "IPY_MODEL_f23caa1c7f3943f0a35df5e9209b1506"
          }
        },
        "2ff43c344d7a47649533c3f563e48867": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "467c930de4464625a622f2458aab28a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b14ac5b1d9943efb0cc499adb124c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ffae02276a8408fa78ae2829c16951c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "539d4137c92a472e80ccf3025e7f550a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f854308a3b15459e9d04db15afe01689",
            "placeholder": "​",
            "style": "IPY_MODEL_ff37553fc5144fa0a29eeffdecbd8284",
            "value": ""
          }
        },
        "553a93cf5a6e4d6195e86e9c84ba3adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21421803d6f450ea9f576a2a98de127",
            "placeholder": "​",
            "style": "IPY_MODEL_dffdde6dccab47ad9cd6ef0c8dee70bf",
            "value": " 4468840/? [13:59&lt;00:00, 5445.27it/s]"
          }
        },
        "594de13f96cc43d89249ea570b0bb1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4a451572264a4090ebbd3538746b93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5f936c2664bb4dad96248ad245629c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff43c344d7a47649533c3f563e48867",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b14ac5b1d9943efb0cc499adb124c28",
            "value": 1
          }
        },
        "6a66ce5c04324787b25bb01321ed2691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e50feb0d118481e9b428e98d8a194ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803e0d8755bd4886902df945fe3bd7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "852e77daec144f089d0662237831a046": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdad38d2e5c74fcfb658ee996002cb7f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93d112fc010f4ed389db9a123ee9475f",
            "value": 1
          }
        },
        "93d112fc010f4ed389db9a123ee9475f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97e700609be747248d700fcdd7e9ae73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c2617188b64744a8c014202f75e9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d4a451572264a4090ebbd3538746b93",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b6451eceb2e4a41be58dd3352f0f2cd",
            "value": 1
          }
        },
        "ac6923958e13466ba7e8ed2019451a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d45fb7c805a4436ac546ccb82076f75",
            "placeholder": "​",
            "style": "IPY_MODEL_f00538d27fed4f0fb768bcbdaacb0f53",
            "value": " 2737/? [00:01&lt;00:00, 2025.35it/s]"
          }
        },
        "b22ce93b28ba4ecabea756ee75641172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_467c930de4464625a622f2458aab28a6",
            "placeholder": "​",
            "style": "IPY_MODEL_803e0d8755bd4886902df945fe3bd7a9",
            "value": ""
          }
        },
        "b81ad2b34be74bfaa790757b5b64298f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfe44cad8a5741ffb02387c267fcd604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_594de13f96cc43d89249ea570b0bb1c6",
            "placeholder": "​",
            "style": "IPY_MODEL_29660b40777a43ed84b8fdb0a0b04a5a",
            "value": ""
          }
        },
        "c377a4ba58db40d59985c538741ced61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4f74adbd434402184e46a8725bbd538",
            "placeholder": "​",
            "style": "IPY_MODEL_ef48e9b3d60049cf80f45f5f5ce85692",
            "value": " 3239358/? [20:06&lt;00:00, 1856.16it/s]"
          }
        },
        "c4091b85a534428d850c98fea1f24673": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce36610875874f6487c7f29a6f394834": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d4f74adbd434402184e46a8725bbd538": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc4551c6a2d74c5cb064c5569100b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e700609be747248d700fcdd7e9ae73",
            "placeholder": "​",
            "style": "IPY_MODEL_6a66ce5c04324787b25bb01321ed2691",
            "value": ""
          }
        },
        "dffdde6dccab47ad9cd6ef0c8dee70bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea07a8226ab9431f88298980914e196e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfe44cad8a5741ffb02387c267fcd604",
              "IPY_MODEL_2cd35d11eb624c5b8f2ecf88ad8203dc",
              "IPY_MODEL_ac6923958e13466ba7e8ed2019451a4c"
            ],
            "layout": "IPY_MODEL_057043f95f9244f1af63816c77dbc79f"
          }
        },
        "ef48e9b3d60049cf80f45f5f5ce85692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f00538d27fed4f0fb768bcbdaacb0f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f21421803d6f450ea9f576a2a98de127": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23caa1c7f3943f0a35df5e9209b1506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f854308a3b15459e9d04db15afe01689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdad38d2e5c74fcfb658ee996002cb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ff37553fc5144fa0a29eeffdecbd8284": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff28b947224840e7930e145be1abeb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c6e76ac7f144378bebdefc0bfce359e",
              "IPY_MODEL_9028c4d7356c40899af72097455e81cc",
              "IPY_MODEL_443d5ef229a6479d861e6cb6470fe962"
            ],
            "layout": "IPY_MODEL_54432c28b5a74313bf67cbdee2e58cd8"
          }
        },
        "2c6e76ac7f144378bebdefc0bfce359e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e82974a814ed4dffbaa3369a76f42597",
            "placeholder": "​",
            "style": "IPY_MODEL_c1d612f9fd344593923bae6a7432310f",
            "value": "100%"
          }
        },
        "9028c4d7356c40899af72097455e81cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3309730587ca4d1990109e1be31b9ee9",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32b752136ff9445db80122898004c61a",
            "value": 50000
          }
        },
        "443d5ef229a6479d861e6cb6470fe962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac26bf0839f5447fb3fdb59426aed8ee",
            "placeholder": "​",
            "style": "IPY_MODEL_c8d40b1fb9854dbabde94b8f2e23b86c",
            "value": " 50000/50000 [00:00&lt;00:00, 196617.10it/s]"
          }
        },
        "54432c28b5a74313bf67cbdee2e58cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82974a814ed4dffbaa3369a76f42597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d612f9fd344593923bae6a7432310f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3309730587ca4d1990109e1be31b9ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b752136ff9445db80122898004c61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac26bf0839f5447fb3fdb59426aed8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d40b1fb9854dbabde94b8f2e23b86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fb52dd18278454085d444c97b75c8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ab6b54b4107405f8ad989265f5f03de",
              "IPY_MODEL_7565f27d6f5741eea8ee7be6a77d01c2",
              "IPY_MODEL_f84c2dc87a384afeaff6be0eacd793f4"
            ],
            "layout": "IPY_MODEL_61d1c0c8084944548e0d8006415512ad"
          }
        },
        "0ab6b54b4107405f8ad989265f5f03de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7607aa00475d4522a95e9e7e00f2cef3",
            "placeholder": "​",
            "style": "IPY_MODEL_cbdd01642da54154a4fcb349aefee808",
            "value": "100%"
          }
        },
        "7565f27d6f5741eea8ee7be6a77d01c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b1dfb5f1d5c4511a63bdff39f9b9de0",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_308726f6179049bb877b4197139e3ded",
            "value": 50000
          }
        },
        "f84c2dc87a384afeaff6be0eacd793f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c0de2862f6470ea07f6354681dd02a",
            "placeholder": "​",
            "style": "IPY_MODEL_5b22df2ae74e46b08eeddaf1f3cc6e2c",
            "value": " 50000/50000 [00:00&lt;00:00, 168328.50it/s]"
          }
        },
        "61d1c0c8084944548e0d8006415512ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7607aa00475d4522a95e9e7e00f2cef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbdd01642da54154a4fcb349aefee808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b1dfb5f1d5c4511a63bdff39f9b9de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308726f6179049bb877b4197139e3ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70c0de2862f6470ea07f6354681dd02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b22df2ae74e46b08eeddaf1f3cc6e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fbced3ac92d4a34b112297a1f9a692c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a83d592dcd040be9608ca1176241a67",
              "IPY_MODEL_629d80f0a77844379d9bf6188a2470f5",
              "IPY_MODEL_3778c6178420426b8aabaa7c3d09bfce"
            ],
            "layout": "IPY_MODEL_a1db28d6ef104e9c9fed42cd3f081724"
          }
        },
        "7a83d592dcd040be9608ca1176241a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d49c47fe6b4d2b8ab3508c993e9185",
            "placeholder": "​",
            "style": "IPY_MODEL_d960a9a9d8ed4b8c99cee2106ed6e48a",
            "value": ""
          }
        },
        "629d80f0a77844379d9bf6188a2470f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313fb0f31b40465b8e4ea9fcfdbe8692",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b4128cd05414acabbe566c48c3e79ff",
            "value": 1
          }
        },
        "3778c6178420426b8aabaa7c3d09bfce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_314de1087d4c4eafa42af96488df4f67",
            "placeholder": "​",
            "style": "IPY_MODEL_7470fe2f15d94d41b23204f7d38b0ecb",
            "value": " 1781990/? [19:32&lt;00:00, 1682.91it/s]"
          }
        },
        "a1db28d6ef104e9c9fed42cd3f081724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d49c47fe6b4d2b8ab3508c993e9185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d960a9a9d8ed4b8c99cee2106ed6e48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "313fb0f31b40465b8e4ea9fcfdbe8692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8b4128cd05414acabbe566c48c3e79ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "314de1087d4c4eafa42af96488df4f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7470fe2f15d94d41b23204f7d38b0ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d4d5985d1874f25ad87de5eeae1c383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce16c3368b5402aafd70cc186316544",
              "IPY_MODEL_7e24b8c2fe6541b480354b54b4cb92f5",
              "IPY_MODEL_fd54dca48bbe44199bac37756b37e4b7"
            ],
            "layout": "IPY_MODEL_6ffa047d8d5849c79e6a3e2f61f18d1e"
          }
        },
        "6ce16c3368b5402aafd70cc186316544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e40bebfdb0b4115805188e79e231dd4",
            "placeholder": "​",
            "style": "IPY_MODEL_c768b05c93c94f5e9202d735c1683882",
            "value": ""
          }
        },
        "7e24b8c2fe6541b480354b54b4cb92f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945d561cabd34e7f97c6f4c20fcc4c58",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bd28c5cdc32412f940c3a93017e3a49",
            "value": 1
          }
        },
        "fd54dca48bbe44199bac37756b37e4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dc2803c33e34d7280cc4f53ae0034d7",
            "placeholder": "​",
            "style": "IPY_MODEL_a857df531c614bc8855f6aae89adab76",
            "value": " 1639/? [00:00&lt;00:00, 1802.43it/s]"
          }
        },
        "6ffa047d8d5849c79e6a3e2f61f18d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e40bebfdb0b4115805188e79e231dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c768b05c93c94f5e9202d735c1683882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "945d561cabd34e7f97c6f4c20fcc4c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6bd28c5cdc32412f940c3a93017e3a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dc2803c33e34d7280cc4f53ae0034d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a857df531c614bc8855f6aae89adab76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}